# üîÑ HANDOFF: Level 2 Implementation Complete

**–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è:** 29 –æ–∫—Ç—è–±—Ä—è 2025  
**–î–ª—è:** –°–ª–µ–¥—É—é—â–∏–π AI-–∞–≥–µ–Ω—Ç  
**–°—Ç–∞—Ç—É—Å:** Level 2 —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω, –≥–æ—Ç–æ–≤ –∫ —Ñ–∏–Ω–∞–ª—å–Ω–æ–º—É —Ç–µ—Å—Ç—É –∏ –ø–µ—Ä–µ—Ö–æ–¥—É –∫ Stage 4 (Dynamic Quiz)

---

## üìã –°–û–î–ï–†–ñ–ê–ù–ò–ï

1. [–ò–∑–Ω–∞—á–∞–ª—å–Ω—ã–µ –ø–ª–∞–Ω—ã](#–∏–∑–Ω–∞—á–∞–ª—å–Ω—ã–µ-–ø–ª–∞–Ω—ã)
2. [–ß—Ç–æ –±—ã–ª–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ](#—á—Ç–æ-–±—ã–ª–æ-—Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ)
3. [–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –∏ –∫–ª—é—á–µ–≤—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã](#–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞-–∏-–∫–ª—é—á–µ–≤—ã–µ-–∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã)
4. [–ò–∑–º–µ–Ω—ë–Ω–Ω—ã–π –∫–æ–¥](#–∏–∑–º–µ–Ω—ë–Ω–Ω—ã–π-–∫–æ–¥)
5. [–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –ø—Ä–æ—Ñ–∏–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è](#–∫–∞–∫-—Ä–∞–±–æ—Ç–∞–µ—Ç-–ø—Ä–æ—Ñ–∏–ª—å-–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è)
6. [–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã](#–ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ-–ø—Ä–æ–±–ª–µ–º—ã)
7. [–ü–ª–∞–Ω –¥–∞–ª—å–Ω–µ–π—à–µ–π —Ä–∞–±–æ—Ç—ã](#–ø–ª–∞–Ω-–¥–∞–ª—å–Ω–µ–π—à–µ–π-—Ä–∞–±–æ—Ç—ã)

---

## üéØ –ò–ó–ù–ê–ß–ê–õ–¨–ù–´–ï –ü–õ–ê–ù–´

### Roadmap –ø—Ä–æ–µ–∫—Ç–∞ (IMPLEMENTATION_ROADMAP.md)

**Stage 1:** ‚úÖ Dual API Support (ChatCompletion + Assistant API fallback)  
**Stage 2:** ‚úÖ Style Settings UI (tone, personality, message length)  
**Stage 3:** ‚úÖ Pattern Analysis (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –≤—ã—è–≤–ª–µ–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è)  
**Stage 4:** üîÑ Dynamic Quiz (–∞–¥–∞–ø—Ç–∏–≤–Ω—ã–µ –æ–ø—Ä–æ—Å–Ω–∏–∫–∏ –¥–ª—è —É–≥–ª—É–±–ª–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞)

### Level 2 Goals (–æ—Å–Ω–æ–≤–Ω–∞—è —Ä–∞–±–æ—Ç–∞)

**–¶–µ–ª—å:** –£–ª—É—á—à–∏—Ç—å –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏—é –±–æ—Ç–∞ —á–µ—Ä–µ–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ **–∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤** (evidence) –∏–∑ –¥–∏–∞–ª–æ–≥–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

**–ö–ª—é—á–µ–≤—ã–µ –∑–∞–¥–∞—á–∏:**
1. ‚úÖ –ò—Å–ø—Ä–∞–≤–∏—Ç—å Quote Hallucination (–±–æ—Ç –ø—Ä–∏–¥—É–º—ã–≤–∞–ª —Ü–∏—Ç–∞—Ç—ã)
2. ‚úÖ –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å Pattern Analysis —Å embeddings (Moderate architecture)
3. ‚úÖ –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å evidence (—Ü–∏—Ç–∞—Ç—ã) –≤ system prompt
4. ‚úÖ –î–æ–±–∞–≤–∏—Ç—å meta-instructions –¥–ª—è GPT (–∫–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–∏–º–µ—Ä—ã)
5. ‚è≥ –£–≤–µ–ª–∏—á–∏—Ç—å occurrences (—á–∞—Å—Ç–æ—Ç–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤) –¥–æ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π

### –û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:
- –ë–æ—Ç –∏—Å–ø–æ–ª—å–∑—É–µ—Ç **—Ä–µ–∞–ª—å–Ω—ã–µ —Ü–∏—Ç–∞—Ç—ã** –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –æ—Ç–≤–µ—Ç–∞—Ö
- –ü–∞—Ç—Ç–µ—Ä–Ω—ã –Ω–∞–∫–∞–ø–ª–∏–≤–∞—é—Ç—Å—è –∏ —Ä–∞—Å—Ç—É—Ç (occurrences ‚â• 5-10)
- –ü–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ **–∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤**, –∞ –Ω–µ –∞–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã—Ö –æ–ø–∏—Å–∞–Ω–∏–π

---

## ‚úÖ –ß–¢–û –ë–´–õ–û –†–ï–ê–õ–ò–ó–û–í–ê–ù–û

### 1. Quote Hallucination Fix (100% accuracy) ‚úÖ

**–ü—Ä–æ–±–ª–µ–º–∞:** –ë–æ—Ç —Ü–∏—Ç–∏—Ä–æ–≤–∞–ª —Ñ—Ä–∞–∑—ã, –∫–æ—Ç–æ—Ä—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –≥–æ–≤–æ—Ä–∏–ª.

**–†–µ—à–µ–Ω–∏–µ:**
- –î–æ–±–∞–≤–ª–µ–Ω–∞ —Å–µ–∫—Ü–∏—è "RECENT USER MESSAGES" –≤ system prompt
- –ü–æ—Å–ª–µ–¥–Ω–∏–µ 5 —Å–æ–æ–±—â–µ–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —è–≤–Ω–æ –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç—Å—è GPT
- –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏: —Ü–∏—Ç–∏—Ä–æ–≤–∞—Ç—å –¢–û–õ–¨–ö–û –∏–∑ —ç—Ç–æ–≥–æ —Å–ø–∏—Å–∫–∞ –∏–ª–∏ –∏–∑ evidence

**–§–∞–π–ª:** `soul_bot/bot/services/openai_service.py` (—Å—Ç—Ä–æ–∫–∏ 195-227)

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** 3 —Ç–µ—Å—Ç–∞ –ø–æ–¥—Ä—è–¥ ‚Äî 0 –ø—Ä–∏–¥—É–º–∞–Ω–Ω—ã—Ö —Ü–∏—Ç–∞—Ç (100% accuracy)

---

### 2. Pattern Analysis System (Moderate + Embeddings) ‚úÖ

**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:** Moderate (–∏–∑ 3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤)

**–ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:**
- `pattern_analyzer.py` ‚Äî –∞–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ —á–µ—Ä–µ–∑ GPT-4o-mini
- `embedding_service.py` ‚Äî –≥–µ–Ω–µ—Ä–∞—Ü–∏—è embeddings –∏ similarity check
- Quick Analysis (–∫–∞–∂–¥—ã–µ 3 —Å–æ–æ–±—â–µ–Ω–∏—è) ‚Äî –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
- Deep Analysis (–∫–∞–∂–¥—ã–µ 20 —Å–æ–æ–±—â–µ–Ω–∏–π) ‚Äî –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–Ω—Å–∞–π—Ç–æ–≤

**–ú–æ–¥–µ–ª—å –¥–∞–Ω–Ω—ã—Ö:**
```json
{
  "patterns": [
    {
      "id": "uuid",
      "type": "behavioral|emotional|cognitive",
      "title": "Imposter Syndrome",
      "description": "Detailed psychological explanation",
      "evidence": ["quote 1", "quote 2"],
      "embedding": [0.1, 0.2, ...],  // 1536 dimensions
      "occurrences": 5,
      "confidence": 0.85,
      "tags": ["clinical-term"],
      "related_patterns": ["pattern_id"],
      "first_detected": "2025-10-28",
      "last_detected": "2025-10-29"
    }
  ]
}
```

**–ê–ª–≥–æ—Ä–∏—Ç–º:**
1. User –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ ‚Üí —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –≤ `conversation_history`
2. –ö–∞–∂–¥—ã–µ 3 —Å–æ–æ–±—â–µ–Ω–∏—è ‚Üí `quick_analysis()`
3. GPT-4o-mini –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–µ 15 —Å–æ–æ–±—â–µ–Ω–∏–π
4. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç 1-2 –ø–∞—Ç—Ç–µ—Ä–Ω–∞ —Å evidence (—Ü–∏—Ç–∞—Ç–∞–º–∏)
5. Embeddings –ø—Ä–æ–≤–µ—Ä—è–µ—Ç similarity —Å existing patterns
6. –ï—Å–ª–∏ similarity > 0.55 ‚Üí –º–µ—Ä–¥–∂ (occurrences++)
7. –ï—Å–ª–∏ –Ω–µ—Ç ‚Üí –¥–æ–±–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω

**–î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è:**
```python
# embedding_service.py
SIMILARITY_THRESHOLD_DUPLICATE = 0.55  # Cosine similarity
SIMILARITY_THRESHOLD_RELATED = 0.50

# pattern_analyzer.py
is_dup, duplicate, similarity = await embedding_service.is_duplicate(
    pattern_text,
    existing_patterns,
    threshold=SIMILARITY_THRESHOLD_DUPLICATE
)

if is_dup:
    duplicate['occurrences'] += 1  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —á–∞—Å—Ç–æ—Ç—É
    duplicate['evidence'].extend(new_evidence)  # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ —Ü–∏—Ç–∞—Ç—ã
```

---

### 3. Contextual Examples –≤ System Prompt ‚úÖ

**–ò–¥–µ—è:** GPT –≤–∏–¥–∏—Ç –Ω–µ —Ç–æ–ª—å–∫–æ –æ–ø–∏—Å–∞–Ω–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤, –Ω–æ –∏ **–∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ü–∏—Ç–∞—Ç—ã** –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

**–†–µ–∞–ª–∏–∑–∞—Ü–∏—è:** `openai_service.py`, —Ñ—É–Ω–∫—Ü–∏—è `build_system_prompt()`

**–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–º–ø—Ç–∞:**
```
1. –ù–ê–°–¢–†–û–ô–ö–ò –°–¢–ò–õ–Ø (tone, personality, length)
2. –ë–ê–ó–û–í–´–ï –ò–ù–°–¢–†–£–ö–¶–ò–ò (—Ä–æ–ª—å –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞)
3. –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–ï (–∏–º—è, –≤–æ–∑—Ä–∞—Å—Ç, –ø–æ–ª)
4. üß† –í–´–Ø–í–õ–ï–ù–ù–´–ï –ü–ê–¢–¢–ï–†–ù–´:
   - Pattern title
   - Description
   - üìù Evidence (—Ü–∏—Ç–∞—Ç—ã –∏–∑ –¥–∏–∞–ª–æ–≥–æ–≤):
     ‚Ä¢ "exact quote 1"
     ‚Ä¢ "exact quote 2"
   - Tags
5. üí¨ –ü–û–°–õ–ï–î–ù–ò–ï –°–û–û–ë–©–ï–ù–ò–Ø –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø (–¥–ª—è —Ç–æ—á–Ω–æ–≥–æ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)
6. üí° –ò–ù–°–ê–ô–¢–´ (—Å recommendations)
7. üòä –≠–ú–û–¶–ò–û–ù–ê–õ–¨–ù–û–ï –°–û–°–¢–û–Ø–ù–ò–ï
8. üéì LEARNING PREFERENCES (—á—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç/–Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç)
```

**–ü—Ä–∏–º–µ—Ä —Å–µ–∫—Ü–∏–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤:**
```
## üß† –í—ã—è–≤–ª–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:

**[EMOTIONAL] Imposter Syndrome**
–û–ø–∏—Å–∞–Ω–∏–µ: –ß—É–≤—Å—Ç–≤–æ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç–∏ –Ω–µ—Å–º–æ—Ç—Ä—è –Ω–∞ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞ –∫–æ–º–ø–µ—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏
–ß–∞—Å—Ç–æ—Ç–∞: –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è 5x (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å 85%)
üìù –ü—Ä–∏–º–µ—Ä—ã –∏–∑ –¥–∏–∞–ª–æ–≥–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:
  ‚Ä¢ "–Ø –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ö–æ—Ä–æ—à –¥–ª—è —ç—Ç–æ–π —Ä–∞–±–æ—Ç—ã"
  ‚Ä¢ "–Ø –æ–±–º–∞–Ω—â–∏–∫, —Å–∫–æ—Ä–æ –≤—Å–µ –ø–æ–π–º—É—Ç —á—Ç–æ —è –Ω–∏—á–µ–≥–æ –Ω–µ –∑–Ω–∞—é"
–¢–µ–≥–∏: imposter-syndrome, self-doubt
```

**Meta-instructions –¥–ª—è GPT:**
```
‚ö†Ô∏è –í–ê–ñ–ù–û: –ò—Å–ø–æ–ª—å–∑—É–π —ç—Ç–∏ –ö–û–ù–ö–†–ï–¢–ù–´–ï –ü–†–ò–ú–ï–†–´ –∏–∑ –¥–∏–∞–ª–æ–≥–æ–≤ –≤ —Å–≤–æ–∏—Ö –æ—Ç–≤–µ—Ç–∞—Ö.
–§–æ—Ä–º–∞—Ç: '–ü–æ–º–Ω–∏—à—å, —Ç—ã –≥–æ–≤–æ—Ä–∏–ª: "[—Ç–æ—á–Ω–∞—è —Ü–∏—Ç–∞—Ç–∞]". –≠—Ç–æ –ø—Ä–æ—è–≤–ª–µ–Ω–∏–µ [–ø–∞—Ç—Ç–µ—Ä–Ω]...'
```

---

### 4. Style Settings Integration ‚úÖ

**UI:** Inline keyboards –≤ Telegram (brief/formal/coach –∏ —Ç.–¥.)

**Backend:** Dynamic system prompt construction

**Length enforcement:**
- –ü—Ä–æ–º–ø—Ç: "‚ö†Ô∏è –ö–†–ò–¢–ò–ß–ù–û: –û—Ç–≤–µ—á–∞–π –°–¢–†–û–ì–û 2-3 –∫–æ—Ä–æ—Ç–∫–∏–º–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º–∏ (–º–∞–∫—Å–∏–º—É–º 40-50 —Å–ª–æ–≤)"
- Post-processing: `_enforce_message_length()` –æ–±—Ä–µ–∑–∞–µ—Ç –µ—Å–ª–∏ –ø—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç

**–§–∞–π–ª—ã:**
- `bot/keyboards/profile.py` ‚Äî UI –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–µ–∫
- `bot/handlers/user/profile.py` ‚Äî –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏
- `bot/services/openai_service.py` ‚Äî –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Å—Ç–∏–ª—è

---

### 5. `/my_profile` Command ‚úÖ

**–§—É–Ω–∫—Ü–∏—è:** –ü–æ–∫–∞–∑–∞—Ç—å user'—É –µ–≥–æ –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –ø—Ä–æ—Ñ–∏–ª—å –≤ —á–∏—Ç–∞–±–µ–ª—å–Ω–æ–º –≤–∏–¥–µ.

**–ê–ª–≥–æ—Ä–∏—Ç–º:**
1. –ü–æ–ª—É—á–∏—Ç—å `user_profile` –∏–∑ –ë–î
2. –û—á–∏—Å—Ç–∏—Ç—å –æ—Ç embeddings (`_clean_profile_for_display`)
3. –û—Ç–ø—Ä–∞–≤–∏—Ç—å –≤ GPT-4o-mini –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
4. GPT –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫—Ä–∞—Å–∏–≤–æ –æ—Ñ–æ—Ä–º–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç (—ç–º–æ–¥–∑–∏, —Å—Ç—Ä—É–∫—Ç—É—Ä–∞)
5. –û—Ç–ø—Ä–∞–≤–∏—Ç—å user'—É

**–§–∞–π–ª:** `bot/handlers/user/profile.py`

**–ü—Ä–æ–±–ª–µ–º–∞ (—Ä–µ—à–µ–Ω–∞):** Context length exceeded  
**–†–µ—à–µ–Ω–∏–µ:** –£–¥–∞–ª—è–µ–º embeddings, truncate evidence –¥–æ 2 –ø—Ä–∏–º–µ—Ä–æ–≤

---

## üèóÔ∏è –ê–†–•–ò–¢–ï–ö–¢–£–†–ê –ò –ö–õ–Æ–ß–ï–í–´–ï –ö–û–ú–ü–û–ù–ï–ù–¢–´

### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞ (—É–ø—Ä–æ—â—ë–Ω–Ω–∞—è)

```
User Message
    ‚Üì
[openai_service.py]
    ‚îú‚îÄ‚Üí build_system_prompt() ‚Üê user_profile (patterns, insights)
    ‚îú‚îÄ‚Üí get_chat_completion() ‚Üí GPT-4
    ‚îî‚îÄ‚Üí save_conversation() ‚Üí conversation_history
         ‚Üì
    [pattern_analyzer.py]
         ‚îú‚îÄ‚Üí analyze_if_needed() (–∫–∞–∂–¥—ã–µ 3 msg)
         ‚îú‚îÄ‚Üí quick_analysis() ‚Üí GPT-4o-mini
         ‚îú‚îÄ‚Üí _add_patterns_with_dedup()
         ‚îÇ    ‚îî‚îÄ‚Üí [embedding_service.py]
         ‚îÇ         ‚îú‚îÄ‚Üí get_embedding() ‚Üí OpenAI
         ‚îÇ         ‚îî‚îÄ‚Üí cosine_similarity()
         ‚îî‚îÄ‚Üí user_profile.update_patterns()
              ‚Üì
         [Database: user_profiles]
```

### –ö–ª—é—á–µ–≤—ã–µ —Å–µ—Ä–≤–∏—Å—ã

#### 1. `openai_service.py`
**–†–æ–ª—å:** –í–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ —Å OpenAI, –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ system prompt

**–ö–ª—é—á–µ–≤—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏:**
- `build_system_prompt(user_id, assistant_type)` ‚Äî –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç
- `get_chat_completion(user_id, message)` ‚Äî –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç GPT
- `_build_style_instructions(profile)` ‚Äî –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ —Å—Ç–∏–ª—è
- `_enforce_message_length(text, length)` ‚Äî post-processing –æ–±—Ä–µ–∑–∫–∞

**–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:**
- `user_profile` repository
- `conversation_history` repository
- `pattern_analyzer` (–¥–ª—è —Ñ–æ–Ω–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞)

#### 2. `pattern_analyzer.py`
**–†–æ–ª—å:** –ê–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

**–ö–ª—é—á–µ–≤—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏:**
- `analyze_if_needed(user_id)` ‚Äî —Ç—Ä–∏–≥–≥–µ—Ä (–∫–∞–∂–¥—ã–µ 3/20 msg)
- `quick_analysis(user_id)` ‚Äî –±—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑ (–ø–∞—Ç—Ç–µ—Ä–Ω—ã + mood)
- `deep_analysis(user_id)` ‚Äî –≥–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ (–∏–Ω—Å–∞–π—Ç—ã)
- `_add_patterns_with_dedup()` ‚Äî –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–µ–π

**–ê–ª–≥–æ—Ä–∏—Ç–º –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏:**
```python
1. –ü–æ–ª—É—á–∏—Ç—å –Ω–æ–≤—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω –æ—Ç GPT
2. –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å embedding (1536 dim vector)
3. –î–ª—è –∫–∞–∂–¥–æ–≥–æ existing pattern:
   - –ü–æ—Å—á–∏—Ç–∞—Ç—å cosine_similarity(new, existing)
   - –ï—Å–ª–∏ similarity > 0.55 ‚Üí —ç—Ç–æ –¥—É–±–ª–∏–∫–∞—Ç
4. –ï—Å–ª–∏ –¥—É–±–ª–∏–∫–∞—Ç –Ω–∞–π–¥–µ–Ω:
   - –ú–µ—Ä–¥–∂–∏—Ç—å: occurrences++, evidence.extend()
5. –ò–Ω–∞—á–µ:
   - –î–æ–±–∞–≤–∏—Ç—å –∫–∞–∫ –Ω–æ–≤—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω
```

**–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:**
- `embedding_service`
- `user_profile` repository
- `conversation_history` repository

#### 3. `embedding_service.py`
**–†–æ–ª—å:** –†–∞–±–æ—Ç–∞ —Å embeddings (OpenAI text-embedding-3-small)

**–ö–ª—é—á–µ–≤—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏:**
- `get_embedding(text)` ‚Üí `list[float]` (1536 dimensions)
- `cosine_similarity(vec1, vec2)` ‚Üí `float` (0.0-1.0)
- `is_duplicate(text, existing_patterns, threshold)` ‚Üí `(bool, dict, float)`

**–ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã:**
```python
SIMILARITY_THRESHOLD_DUPLICATE = 0.55  # –î–ª—è –º–µ—Ä–¥–∂–∞
SIMILARITY_THRESHOLD_RELATED = 0.50    # –î–ª—è related_patterns
```

---

## üìù –ò–ó–ú–ï–ù–Å–ù–ù–´–ô –ö–û–î

### –ù–æ–≤—ã–µ —Ñ–∞–π–ª—ã:

1. **`bot/services/embedding_service.py`** (NEW)
   - –ì–µ–Ω–µ—Ä–∞—Ü–∏—è embeddings
   - Cosine similarity
   - ~150 —Å—Ç—Ä–æ–∫

2. **`bot/services/pattern_analyzer.py`** (NEW)
   - Quick/Deep analysis
   - –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
   - ~600 —Å—Ç—Ä–æ–∫

3. **`database/migrations/001_add_moderate_fields.sql`** (NEW)
   - –î–æ–±–∞–≤–ª–µ–Ω–∏–µ JSONB –ø–æ–ª–µ–π (emotional_state, conversation_metrics, learning_preferences)

### –ó–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –∏–∑–º–µ–Ω—ë–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã:

1. **`bot/services/openai_service.py`**
   - `build_system_prompt()` ‚Äî –¥–æ–±–∞–≤–ª–µ–Ω—ã —Å–µ–∫—Ü–∏–∏:
     - –ü–∞—Ç—Ç–µ—Ä–Ω—ã —Å evidence (—Å—Ç—Ä–æ–∫–∏ 94-145)
     - Recent user messages (—Å—Ç—Ä–æ–∫–∏ 195-227)
     - Emotional state (—Å—Ç—Ä–æ–∫–∏ 196-214)
     - Learning preferences (—Å—Ç—Ä–æ–∫–∏ 216-230)
   - `_enforce_message_length()` ‚Äî post-processing (—Å—Ç—Ä–æ–∫–∏ 469-522)
   - **–ò–∑–º–µ–Ω–µ–Ω–∏–π:** ~200 —Å—Ç—Ä–æ–∫ –¥–æ–±–∞–≤–ª–µ–Ω–æ

2. **`database/models/user_profile.py`**
   - –î–æ–±–∞–≤–ª–µ–Ω—ã JSONB –ø–æ–ª—è:
     - `patterns` (—Å embeddings)
     - `insights`
     - `emotional_state`
     - `conversation_metrics`
     - `learning_preferences`
   - **–ò–∑–º–µ–Ω–µ–Ω–∏–π:** ~50 —Å—Ç—Ä–æ–∫

3. **`database/repository/user_profile.py`**
   - `update_patterns(user_id, patterns)` (NEW)
   - `update_insights(user_id, insights)` (NEW)
   - **–ò–∑–º–µ–Ω–µ–Ω–∏–π:** ~30 —Å—Ç—Ä–æ–∫

4. **`bot/handlers/user/profile.py`**
   - Style settings handlers (tone, personality, length)
   - `/my_profile` command
   - `_clean_profile_for_display()` ‚Äî —É–¥–∞–ª–µ–Ω–∏–µ embeddings
   - `_format_profile_with_gpt()` ‚Äî —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ GPT
   - **–ò–∑–º–µ–Ω–µ–Ω–∏–π:** ~200 —Å—Ç—Ä–æ–∫ –¥–æ–±–∞–≤–ª–µ–Ω–æ

5. **`bot/keyboards/profile.py`**
   - `style_settings_menu`
   - `tone_menu`, `personality_menu`, `length_menu`
   - **–ò–∑–º–µ–Ω–µ–Ω–∏–π:** ~80 —Å—Ç—Ä–æ–∫

### –ò–∑–º–µ–Ω–µ–Ω–∏—è –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏:

**`.env.test` / `.env.prod`:**
```
ENABLE_PATTERN_ANALYSIS=true
USE_CHAT_COMPLETION=true
```

**`requirements.txt`:**
```
numpy==2.2.1  # –î–ª—è cosine similarity
```

---

## üß† –ö–ê–ö –†–ê–ë–û–¢–ê–ï–¢ –ü–†–û–§–ò–õ–¨ –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø

### 1. –°–æ–∑–¥–∞–Ω–∏–µ –∏ –Ω–∞–∫–æ–ø–ª–µ–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤

**–¢—Ä–∏–≥–≥–µ—Ä—ã –∞–Ω–∞–ª–∏–∑–∞:**
```python
# pattern_analyzer.py, analyze_if_needed()
# Quick analysis –∫–∞–∂–¥—ã–µ 3 —Å–æ–æ–±—â–µ–Ω–∏—è
if message_count % 3 == 0:
    await quick_analysis(user_id, assistant_type)

# Deep analysis –∫–∞–∂–¥—ã–µ 20 —Å–æ–æ–±—â–µ–Ω–∏–π  
if message_count % 20 == 0:
    await deep_analysis(user_id, assistant_type)
```

**Quick Analysis Flow:**
```
1. –ü–æ–ª—É—á–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ 15 —Å–æ–æ–±—â–µ–Ω–∏–π (user + bot)
2. –°—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–º–ø—Ç –¥–ª—è GPT-4o-mini:
   - Conversation (last 10 messages)
   - Existing patterns (—á—Ç–æ–±—ã –Ω–µ –¥—É–±–ª–∏—Ä–æ–≤–∞—Ç—å)
   - Task: Find 1-2 BROAD patterns
3. GPT –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç JSON:
   {
     "new_patterns": [
       {
         "title": "Imposter Syndrome",
         "description": "...",
         "evidence": ["quote1", "quote2"],
         "type": "emotional",
         "confidence": 0.85
       }
     ],
     "mood": {...}
   }
4. –î–ª—è –∫–∞–∂–¥–æ–≥–æ –Ω–æ–≤–æ–≥–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞:
   - –ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å embedding (1536 dim)
   - –ü—Ä–æ–≤–µ—Ä–∏—Ç—å similarity —Å existing
   - –ï—Å–ª–∏ similarity > 0.55 ‚Üí –º–µ—Ä–¥–∂ (occurrences++)
   - –ò–Ω–∞—á–µ ‚Üí –¥–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–π
5. –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ user_profile.patterns
```

**Deep Analysis Flow:**
```
1. –ü–æ–ª—É—á–∏—Ç—å –í–°–ï –ø–∞—Ç—Ç–µ—Ä–Ω—ã user'–∞
2. –°—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–º–ø—Ç –¥–ª—è GPT-4o-mini:
   - All patterns
   - Task: Generate insights, recommendations
3. GPT –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç JSON:
   {
     "insights": [
       {
         "title": "...",
         "description": "...",
         "impact": "high",
         "recommendations": ["rec1", "rec2"],
         "derived_from": ["pattern_id1", "pattern_id2"]
       }
     ],
     "learning_preferences": {...}
   }
4. –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ user_profile.insights, learning_preferences
```

### 2. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø—Ä–æ—Ñ–∏–ª—è –¥–ª—è –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏–∏

**–í `build_system_prompt()`:**
```python
# 1. –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–æ—Ñ–∏–ª—å
profile = await user_profile.get_or_create(user_id)

# 2. –°—Ç—Ä–æ–∏–º –ø—Ä–æ–º–ø—Ç –ø–æ —á–∞—Å—Ç—è–º
prompt_parts = []

# 3. –î–æ–±–∞–≤–ª—è–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Å—Ç–∏–ª—è (tone, personality, length)
style_instructions = _build_style_instructions(profile)
prompt_parts.append(style_instructions)

# 4. –î–æ–±–∞–≤–ª—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Å evidence
patterns = profile.patterns.get('patterns', [])
top_patterns = sorted(patterns, key=lambda p: p['occurrences'], reverse=True)[:5]
for pattern in top_patterns:
    pattern_text = f"""
**[{pattern['type']}] {pattern['title']}**
–û–ø–∏—Å–∞–Ω–∏–µ: {pattern['description']}
–ß–∞—Å—Ç–æ—Ç–∞: {pattern['occurrences']}x
üìù –ü—Ä–∏–º–µ—Ä—ã –∏–∑ –¥–∏–∞–ª–æ–≥–æ–≤:
  ‚Ä¢ "{pattern['evidence'][0]}"
  ‚Ä¢ "{pattern['evidence'][1]}"
"""
    prompt_parts.append(pattern_text)

# 5. –î–æ–±–∞–≤–ª—è–µ–º recent user messages (–¥–ª—è —Ç–æ—á–Ω–æ–≥–æ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)
recent_history = await conversation_history.get_context(user_id, max_messages=10)
recent_user_messages = [msg for msg in recent_history if msg['role'] == 'user'][-5:]
prompt_parts.append(format_recent_messages(recent_user_messages))

# 6. –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Å–∞–π—Ç—ã, emotional state, learning preferences
# ...

# 7. –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å—ë –≤ –æ–¥–∏–Ω system prompt
system_prompt = "\n\n".join(prompt_parts)
return system_prompt
```

**GPT –≤–∏–¥–∏—Ç:**
```
## üé® –ù–ê–°–¢–†–û–ô–ö–ò –°–¢–ò–õ–Ø:
‚ö†Ô∏è –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û: –ò—Å–ø–æ–ª—å–∑—É–π –°–¢–†–û–ì–û —Ñ–æ—Ä–º–∞–ª—å–Ω—ã–π —Ç–æ–Ω.
‚ö†Ô∏è –ö–†–ò–¢–ò–ß–ù–û: –û—Ç–≤–µ—á–∞–π –°–¢–†–û–ì–û 2-3 –∫–æ—Ä–æ—Ç–∫–∏–º–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º–∏ (–º–∞–∫—Å–∏–º—É–º 40-50 —Å–ª–æ–≤).

## üß† –í—ã—è–≤–ª–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:
**[EMOTIONAL] Imposter Syndrome**
–û–ø–∏—Å–∞–Ω–∏–µ: –ß—É–≤—Å—Ç–≤–æ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç–∏...
–ß–∞—Å—Ç–æ—Ç–∞: 5x
üìù –ü—Ä–∏–º–µ—Ä—ã –∏–∑ –¥–∏–∞–ª–æ–≥–æ–≤:
  ‚Ä¢ "–Ø –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ö–æ—Ä–æ—à –¥–ª—è —ç—Ç–æ–π —Ä–∞–±–æ—Ç—ã"
  ‚Ä¢ "–Ø –æ–±–º–∞–Ω—â–∏–∫, —Å–∫–æ—Ä–æ –≤—Å–µ –ø–æ–π–º—É—Ç"

## üí¨ –ü–û–°–õ–ï–î–ù–ò–ï –°–û–û–ë–©–ï–ù–ò–Ø –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø:
1. "–ë–æ—é—Å—å –∑–∞–¥–∞–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã –≤ —Å–ª–∞–∫–µ"
2. "–ö–æ–¥ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∏–¥–µ–∞–ª—å–Ω—ã–º"
...

‚ö†Ô∏è –ö–†–ò–¢–ò–ß–ù–û–ï –ü–†–ê–í–ò–õ–û –¶–ò–¢–ò–†–û–í–ê–ù–ò–Ø:
–ï—Å–ª–∏ —Ü–∏—Ç–∏—Ä—É–µ—à—å - –∏—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û —Ñ—Ä–∞–∑—ã –∏–∑ —Å–ø–∏—Å–∫–∞ –≤—ã—à–µ!
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** GPT –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ:
- –ü–∞—Ç—Ç–µ—Ä–Ω–æ–≤ (–∑–Ω–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã user'–∞)
- Evidence (–º–æ–∂–µ—Ç —Ü–∏—Ç–∏—Ä–æ–≤–∞—Ç—å —Ç–æ—á–Ω—ã–µ —Ñ—Ä–∞–∑—ã)
- –°—Ç–∏–ª—è (—Å–æ–±–ª—é–¥–∞–µ—Ç tone/personality/length)
- –ö–æ–Ω—Ç–µ–∫—Å—Ç–∞ (–≤–∏–¥–∏—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è)

### 3. –•—Ä–∞–Ω–µ–Ω–∏–µ –≤ –ë–î

**–¢–∞–±–ª–∏—Ü–∞:** `user_profiles`

**–ö–ª—é—á–µ–≤—ã–µ –ø–æ–ª—è:**
```sql
user_id BIGINT PRIMARY KEY
tone_style VARCHAR(32)  -- 'formal', 'friendly', 'sarcastic', 'motivating'
personality VARCHAR(32) -- 'mentor', 'friend', 'coach'
message_length VARCHAR(32)  -- 'ultra_brief', 'brief', 'medium', 'detailed'
patterns JSONB  -- {"patterns": [...]}
insights JSONB  -- {"insights": [...]}
emotional_state JSONB  -- {"current_mood": "...", "stress_level": "..."}
conversation_metrics JSONB  -- {"total_messages": 100, "avg_sentiment": 0.5}
learning_preferences JSONB  -- {"works_well": [...], "doesnt_work": [...]}
```

**–†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö:**
- –ë–µ–∑ embeddings: ~50-100 KB per user (acceptable)
- –° embeddings: ~500 KB - 1 MB per user (—Ö—Ä–∞–Ω–∏—Ç—Å—è –≤ –ë–î, –Ω–æ —É–¥–∞–ª—è–µ—Ç—Å—è –ø—Ä–∏ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–∏)

---

## ‚ö†Ô∏è –ü–û–¢–ï–ù–¶–ò–ê–õ–¨–ù–´–ï –ü–†–û–ë–õ–ï–ú–´

### üî• –ö–†–ò–¢–ò–ß–ù–ê–Ø –ü–†–û–ë–õ–ï–ú–ê: Occurrences –Ω–µ —Ä–∞—Å—Ç—É—Ç (—Ç–µ–∫—É—â–∞—è)

**–°–∏–º–ø—Ç–æ–º—ã:**
- User –ø–æ–≤—Ç–æ—Ä—è–µ—Ç —Ñ—Ä–∞–∑—É 10-20 —Ä–∞–∑
- –í –ø—Ä–æ—Ñ–∏–ª–µ: occurrences = 1-2 (–¥–æ–ª–∂–Ω–æ 8-10)

**–í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:**

#### 1. GPT –Ω–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã –Ω–∞ repeated themes
**–ì–¥–µ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å:**
```python
# pattern_analyzer.py, quick_analysis()
# –î–æ–±–∞–≤–ª–µ–Ω–æ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ:
logger.info(f"[QUICK ANALYSIS] GPT returned {len(analysis['new_patterns'])} new patterns")
```

**–ö–∞–∫ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å:**
```bash
tail -f soul_bot/soul_test_bot_logs.txt | grep "QUICK ANALYSIS"
```

–ï—Å–ª–∏ –≤–∏–¥–∏—à—å `GPT returned 0 new patterns` —á–∞—Å—Ç–æ ‚Üí GPT –∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ "CREATE AGAIN".

**–í–æ–∑–º–æ–∂–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è:**
- –£—Å–∏–ª–∏—Ç—å –ø—Ä–æ–º–ø—Ç (–µ—â—ë –±–æ–ª–µ–µ explicit)
- –î–æ–±–∞–≤–∏—Ç—å –ø—Ä–∏–º–µ—Ä—ã –≤ –ø—Ä–æ–º–ø—Ç
- –ò–∑–º–µ–Ω–∏—Ç—å temperature (0.3 ‚Üí 0.5 –¥–ª—è –±–æ–ª–µ–µ —Ç–≤–æ—Ä—á–µ—Å–∫–∏—Ö –æ—Ç–≤–µ—Ç–æ–≤)

#### 2. Embeddings –Ω–µ –Ω–∞—Ö–æ–¥—è—Ç similarity (threshold —Å–ª–∏—à–∫–æ–º –Ω–∏–∑–∫–∏–π)
**–ì–¥–µ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å:**
```python
# pattern_analyzer.py, _add_patterns_with_dedup()
# –î–æ–±–∞–≤–ª–µ–Ω–æ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ:
logger.info(f"‚úÖ MERGED: ... | similarity: {similarity:.2f} | occurrences: {old} ‚Üí {new}")
```

**–ö–∞–∫ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å:**
–ï—Å–ª–∏ –≤ –ª–æ–≥–∞—Ö –ù–ï–¢ `‚úÖ MERGED` —Å–æ–æ–±—â–µ–Ω–∏–π ‚Üí embeddings –Ω–µ –Ω–∞—Ö–æ–¥—è—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã.

**–í–æ–∑–º–æ–∂–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è:**
- –°–Ω–∏–∑–∏—Ç—å threshold: 0.55 ‚Üí 0.50 (–±–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π –º–µ—Ä–¥–∂)
- –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ embeddings (–º–æ–∂–µ—Ç, description –ø–ª–æ—Ö–æ –æ–ø–∏—Å—ã–≤–∞–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω)
- –î–æ–±–∞–≤–∏—Ç—å keyword-based fallback (–µ—Å–ª–∏ "Imposter Syndrome" –≤ title ‚Üí force merge)

#### 3. –ß–∞—Å—Ç–æ—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–∞
**–¢–µ–∫—É—â–µ–µ:** –ö–∞–∂–¥—ã–µ 3 —Å–æ–æ–±—â–µ–Ω–∏—è ‚Üí 30 msg / 3 = 10 –∑–∞–ø—É—Å–∫–æ–≤

**–í–æ–∑–º–æ–∂–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è:**
- –£–≤–µ–ª–∏—á–∏—Ç—å —á–∞—Å—Ç–æ—Ç—É: –∫–∞–∂–¥—ã–µ 2 —Å–æ–æ–±—â–µ–Ω–∏—è (30/2 = 15 –∑–∞–ø—É—Å–∫–æ–≤)
- –î–æ–±–∞–≤–∏—Ç—å incremental analysis (–∞–Ω–∞–ª–∏–∑ –ø–æ—Å–ª–µ –ö–ê–ñ–î–û–ì–û user message, –Ω–æ –ª–µ–≥–∫–æ–≤–µ—Å–Ω—ã–π)

#### 4. –ö–æ–Ω—Ñ–ª–∏–∫—Ç –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π –≤ –ø—Ä–æ–º–ø—Ç–µ
**–ß—Ç–æ –¥–µ–ª–∞—Ç—å:**
–ü–µ—Ä–µ—á–∏—Ç–∞—Ç—å –≤–µ—Å—å –ø—Ä–æ–º–ø—Ç –≤ `_analyze_conversation_quick()` –∏ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è.

**–ü—Ä–∏–º–µ—Ä –∫–æ–Ω—Ñ–ª–∏–∫—Ç–∞ (—É–∂–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω):**
```
–°—Ç—Ä–æ–∫–∞ 140: "CREATE pattern AGAIN if it repeats"
–°—Ç—Ä–æ–∫–∞ 162: "If theme repeats ‚Üí SKIP"  ‚ùå –ü–†–û–¢–ò–í–û–†–ï–ß–ò–ï!
```

---

### ‚ö†Ô∏è –ü–†–û–ë–õ–ï–ú–ê: Context length –º–æ–∂–µ—Ç —Ä–∞—Å—Ç–∏

**–°–∏–º–ø—Ç–æ–º—ã:**
- –ü–æ—Å–ª–µ 100+ —Å–æ–æ–±—â–µ–Ω–∏–π system prompt –º–æ–∂–µ—Ç –ø—Ä–µ–≤—ã—Å–∏—Ç—å 128K tokens

**–ü—Ä–∏—á–∏–Ω—ã:**
- –ú–Ω–æ–≥–æ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ (20+)
- –ú–Ω–æ–≥–æ evidence –Ω–∞ –ø–∞—Ç—Ç–µ—Ä–Ω (10+ —Ü–∏—Ç–∞—Ç)
- –î–ª–∏–Ω–Ω—ã–µ descriptions

**–†–µ—à–µ–Ω–∏–µ (—É–∂–µ —á–∞—Å—Ç–∏—á–Ω–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ):**
```python
# –í build_system_prompt()
top_patterns = sorted(patterns, key=lambda p: p['occurrences'], reverse=True)[:5]
# –ë–µ—Ä—ë–º —Ç–æ–ª—å–∫–æ —Ç–æ–ø-5 –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤

for pattern in top_patterns:
    evidence = pattern['evidence'][:3]  # –¢–æ–ª—å–∫–æ 3 –ø—Ä–∏–º–µ—Ä–∞
```

**–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ä—ã (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ):**
- Limit total patterns to 10 (—É–¥–∞–ª—è—Ç—å —Å—Ç–∞—Ä—ã–µ —Å –Ω–∏–∑–∫–∏–º confidence)
- Truncate descriptions to 200 chars
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å summarization –¥–ª—è old patterns

---

### ‚ö†Ô∏è –ü–†–û–ë–õ–ï–ú–ê: Embeddings –∑–∞–Ω–∏–º–∞—é—Ç –º–µ—Å—Ç–æ –≤ –ë–î

**–¢–µ–∫—É—â–µ–µ:** ~1536 floats * 4 bytes = 6 KB per pattern

**–ï—Å–ª–∏ 20 –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤:** 120 KB per user (acceptable, –Ω–æ –Ω–µ ideal)

**–†–µ—à–µ–Ω–∏—è:**
1. **Dimension reduction:** Use OpenAI smaller model (512 dim instead of 1536)
2. **Compress embeddings:** Store as bytes instead of JSON array
3. **External storage:** Store embeddings in vector DB (Pinecone, Weaviate)

---

### ‚ö†Ô∏è –ü–†–û–ë–õ–ï–ú–ê: GPT –º–æ–∂–µ—Ç —Å–æ–∑–¥–∞–≤–∞—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω—ã –Ω–∞ —Ä—É—Å—Å–∫–æ–º

**–°–∏–º–ø—Ç–æ–º—ã:**
- "–°–∏–Ω–¥—Ä–æ–º —Å–∞–º–æ–∑–≤–∞–Ω—Ü–∞" –≤–º–µ—Å—Ç–æ "Imposter Syndrome"
- Embeddings –Ω–µ –º–µ—Ä–¥–∂–∞—Ç –∏–∑-–∑–∞ —Ä–∞–∑–Ω–æ–≥–æ —è–∑—ã–∫–∞

**–†–µ—à–µ–Ω–∏–µ (—Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ):**
```python
# –í –ø—Ä–æ–º–ø—Ç–µ:
üåê LANGUAGE RULE: ALL pattern titles MUST be in ENGLISH!
```

**–ù–æ:** GPT –º–æ–∂–µ—Ç –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å. –ù—É–∂–µ–Ω fallback:
```python
# –î–æ–±–∞–≤–∏—Ç—å –≤ _add_patterns_with_dedup():
if not is_english(new_pattern['title']):
    new_pattern['title'] = translate_to_english(new_pattern['title'])
```

---

### ‚ö†Ô∏è –ü–†–û–ë–õ–ï–ú–ê: Post-processing truncation –º–æ–∂–µ—Ç –ª–æ–º–∞—Ç—å —Å–º—ã—Å–ª

**–¢–µ–∫—É—â–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è:**
```python
def _enforce_message_length(text, message_length):
    # –û–±—Ä–µ–∑–∞–µ—Ç –ø–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º
    sentences = text.split('.')
    # –°–æ–±–∏—Ä–∞–µ—Ç –ø–æ–∫–∞ –Ω–µ –ø—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç —Å–ª–æ–≤
```

**–ü—Ä–æ–±–ª–µ–º–∞:** –ú–æ–∂–µ—Ç –æ–±–æ—Ä–≤–∞—Ç—å –Ω–∞ —Å–µ—Ä–µ–¥–∏–Ω–µ –º—ã—Å–ª–∏.

**–†–µ—à–µ–Ω–∏–µ:**
- –î–æ–±–∞–≤–∏—Ç—å semantic check (–ø–æ—Å–ª–µ–¥–Ω–µ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –∑–∞–∫–æ–Ω—á–µ–Ω–Ω–æ–π –º—ã—Å–ª—å—é)
- –ò–ª–∏ –¥–æ–±–∞–≤–∏—Ç—å "..." –≤ –∫–æ–Ω–µ—Ü –µ—Å–ª–∏ –æ–±—Ä–µ–∑–∞–ª–∏

---

## üó∫Ô∏è –ü–õ–ê–ù –î–ê–õ–¨–ù–ï–ô–®–ï–ô –†–ê–ë–û–¢–´

### –§–∞–∑–∞ 1: –§–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è Level 2 (1-2 –¥–Ω—è)

#### 1.1 Debugging occurrences (HIGH PRIORITY)
**–¶–µ–ª—å:** Occurrences –¥–æ–ª–∂–Ω—ã —Ä–∞—Å—Ç–∏ –¥–æ 5-10

**–ü–ª–∞–Ω:**
1. –ó–∞–ø—É—Å—Ç–∏—Ç—å —Ç–µ—Å—Ç #4 —Å ultra_brief (–±—ã—Å—Ç—Ä–æ)
2. –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ª–æ–≥–∏:
   ```bash
   tail -f soul_test_bot_logs.txt | grep "QUICK ANALYSIS\|MERGED"
   ```
3. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å:
   - –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ª–∏ GPT –ø–∞—Ç—Ç–µ—Ä–Ω—ã? (`GPT returned X new patterns`)
   - –ü—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –ª–∏ –º–µ—Ä–¥–∂? (`‚úÖ MERGED` —Å–æ–æ–±—â–µ–Ω–∏—è)
   - –†–∞—Å—Ç—É—Ç –ª–∏ occurrences? (`occurrences: 3 ‚Üí 4`)

**–ï—Å–ª–∏ –ø—Ä–æ–±–ª–µ–º–∞ –≤ GPT (–Ω–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã):**
- –£—Å–∏–ª–∏—Ç—å –ø—Ä–æ–º–ø—Ç (–¥–æ–±–∞–≤–∏—Ç—å –µ—â—ë –ø—Ä–∏–º–µ—Ä—ã)
- –ò–∑–º–µ–Ω–∏—Ç—å temperature
- –î–æ–±–∞–≤–∏—Ç—å "forced patterns" –¥–ª—è –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö —Ç–µ–º

**–ï—Å–ª–∏ –ø—Ä–æ–±–ª–µ–º–∞ –≤ embeddings (–Ω–µ –º–µ—Ä–¥–∂–∞—Ç):**
- –°–Ω–∏–∑–∏—Ç—å threshold (0.55 ‚Üí 0.50)
- –î–æ–±–∞–≤–∏—Ç—å keyword-based fallback
- –ü—Ä–æ–≤–µ—Ä–∏—Ç—å quality of embeddings

**–ï—Å–ª–∏ –ø—Ä–æ–±–ª–µ–º–∞ –≤ —á–∞—Å—Ç–æ—Ç–µ:**
- –£–≤–µ–ª–∏—á–∏—Ç—å —á–∞—Å—Ç–æ—Ç—É –∞–Ω–∞–ª–∏–∑–∞ (3 ‚Üí 2 —Å–æ–æ–±—â–µ–Ω–∏—è)
- –î–æ–±–∞–≤–∏—Ç—å incremental analysis

**–û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:** occurrences ‚â• 5-8 –≤ —Ç–µ—Å—Ç–µ —Å 30 —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏

---

#### 1.2 Code review –∏ —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥ (MEDIUM PRIORITY)

**–ü—Ä–æ–±–ª–µ–º—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏:**

**1. Pattern Analyzer –∫–æ–¥ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å–ª–æ–∂–Ω—ã–π:**
```python
# pattern_analyzer.py ~600 —Å—Ç—Ä–æ–∫
# –ú–æ–∂–Ω–æ —Ä–∞–∑–±–∏—Ç—å –Ω–∞ –º–æ–¥—É–ª–∏:
pattern_analyzer/
  __init__.py
  quick_analysis.py  # Quick analysis logic
  deep_analysis.py   # Deep analysis logic
  deduplication.py   # Merging logic
  prompts.py         # GPT prompts (–≤—ã–Ω–µ—Å—Ç–∏ –∏–∑ –∫–æ–¥–∞)
```

**2. System prompt –æ—á–µ–Ω—å –¥–ª–∏–Ω–Ω—ã–π (~2000 tokens):**
- –í—ã–Ω–µ—Å—Ç–∏ –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–µ template —Ñ–∞–π–ª—ã?
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Jinja2 –¥–ª—è templating?

**3. Hardcoded strings –≤ –∫–æ–¥–µ:**
```python
# –í—ã–Ω–µ—Å—Ç–∏ –≤ config –∏–ª–∏ constants.py:
PATTERN_EXPECTED_TYPES = [
    "Imposter Syndrome",
    "Perfectionism",
    "Social Anxiety in Professional Settings",
    ...
]
```

**4. –ù–µ—Ç unit tests –¥–ª—è key functions:**
```python
# –î–æ–±–∞–≤–∏—Ç—å tests/unit/test_pattern_analyzer.py:
def test_add_patterns_with_dedup_merges_similar():
    # Test merging logic
    pass

def test_similarity_threshold_works():
    # Test embedding similarity
    pass
```

---

#### 1.3 Performance optimization (LOW PRIORITY)

**–¢–µ–∫—É—â–∏–µ —É–∑–∫–∏–µ –º–µ—Å—Ç–∞:**

**1. Embeddings generation –º–µ–¥–ª–µ–Ω–Ω–æ–µ:**
```python
# –°–µ–π—á–∞—Å: await get_embedding() –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –Ω–æ–≤–æ–≥–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞
# –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è: Batch embeddings
embeddings = await get_embeddings_batch([pattern1, pattern2, ...])
```

**2. Database queries –≤ —Ü–∏–∫–ª–µ:**
```python
# –í _add_patterns_with_dedup() –¥–µ–ª–∞–µ–º update –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞
# –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è: Collect all changes, single update at the end
```

**3. System prompt rebuild –∫–∞–∂–¥—ã–π —Ä–∞–∑:**
```python
# –ú–æ–∂–Ω–æ –∫–µ—à–∏—Ä–æ–≤–∞—Ç—å —á–∞—Å—Ç–∏ –ø—Ä–æ–º–ø—Ç–∞:
@lru_cache(maxsize=100)
def get_cached_base_instructions(assistant_type):
    return _get_base_instructions(assistant_type)
```

---

### –§–∞–∑–∞ 2: –§–∏–Ω–∞–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ (1 –¥–µ–Ω—å)

#### 2.1 Regression testing
**–¶–µ–ª—å:** –£–±–µ–¥–∏—Ç—å—Å—è —á—Ç–æ –Ω–∏—á–µ–≥–æ –Ω–µ —Å–ª–æ–º–∞–ª–æ—Å—å

**Smoke tests:**
```bash
cd soul_bot && pytest tests/smoke_tests.py -v
```

**Manual tests:**
1. Quote accuracy (–¥–æ–ª–∂–Ω–æ –±—ã—Ç—å 100%)
2. Style settings (brief/formal/coach —Ä–∞–±–æ—Ç–∞—é—Ç)
3. `/my_profile` (–ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –ø—Ä–æ—Ñ–∏–ª—å)
4. Pattern occurrences (‚â• 5-8)

#### 2.2 Edge cases testing

**–¢–µ—Å—Ç-–∫–µ–π—Å—ã:**
1. –ù–æ–≤—ã–π user (–Ω–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤) ‚Üí –¥–æ–ª–∂–µ–Ω –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ —Å–æ–∑–¥–∞–≤–∞—Ç—å –ø–µ—Ä–≤—ã–µ
2. User —Å 50+ —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏ ‚Üí –¥–æ–ª–∂–µ–Ω –∏–º–µ—Ç—å consolidated patterns
3. User –º–µ–Ω—è–µ—Ç —è–∑—ã–∫ (—Ä—É—Å‚Üí–∞–Ω–≥–ª) ‚Üí –¥–æ–ª–∂–µ–Ω –ø—Ä–æ–¥–æ–ª–∂–∞—Ç—å —Ä–∞–±–æ—Ç–∞—Ç—å
4. User —Å –æ—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∏–º–∏ —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏ ‚Üí –¥–æ–ª–∂–µ–Ω –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å
5. User —Å –æ—á–µ–Ω—å –¥–ª–∏–Ω–Ω—ã–º–∏ —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏ ‚Üí –Ω–µ –¥–æ–ª–∂–µ–Ω –ø—Ä–µ–≤—ã—à–∞—Ç—å context limit

#### 2.3 Performance testing

**–ú–µ—Ç—Ä–∏–∫–∏:**
- –í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞ –±–æ—Ç–∞ (–¥–æ–ª–∂–Ω–æ –±—ã—Ç—å < 5 —Å–µ–∫ –¥–ª—è ultra_brief)
- Database query time (< 100ms)
- Embedding generation time (< 500ms per pattern)

---

### –§–∞–∑–∞ 3: –ü–µ—Ä–µ—Ö–æ–¥ –∫ Stage 4 (Dynamic Quiz) (3-5 –¥–Ω–µ–π)

#### 3.1 –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π

**–¶–µ–ª—å Stage 4:** –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–µ –æ–ø—Ä–æ—Å–Ω–∏–∫–∏ –¥–ª—è —É–≥–ª—É–±–ª–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞

**–í–æ–ø—Ä–æ—Å—ã –¥–ª—è —É—Ç–æ—á–Ω–µ–Ω–∏—è:**
1. –ö–æ–≥–¥–∞ —Ç—Ä–∏–≥–≥–µ—Ä–∏—Ç—Å—è –∫–≤–∏–∑? (user –∑–∞–ø—Ä–æ—Å, –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏, –ø–æ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—é?)
2. –°–∫–æ–ª—å–∫–æ –≤–æ–ø—Ä–æ—Å–æ–≤? (5-10? 20-30?)
3. –ö–∞–∫–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∫–≤–∏–∑–æ–≤? (relationships, money, confidence, fears, ...)
4. Adaptive logic: –∫–∞–∫ –≤–æ–ø—Ä–æ—Å—ã –º–µ–Ω—è—é—Ç—Å—è based on answers?
5. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–≤–∏–∑–∞: –∫–∞–∫ –∏–Ω—Ç–µ–≥—Ä–∏—Ä—É—é—Ç—Å—è –≤ profile?

**–ü—Ä–∏–º–µ—Ä–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:**
```
QuizSession:
  - id, user_id, category, status
  - current_question_index
  - data (JSONB): {questions: [...], answers: [...]}
  - results (JSONB): generated analysis

QuizService:
  - generate_questions(user_id, category, profile) ‚Üí questions
  - evaluate_answers(session) ‚Üí insights
  - integrate_into_profile(user_id, insights)

QuizHandlers:
  - /quiz command
  - start_quiz_callback
  - handle_quiz_answer (FSM states)
  - finish_quiz ‚Üí show results
```

#### 3.2 –î–∏–∑–∞–π–Ω Database Schema

**Proposal (—É–∂–µ –µ—Å—Ç—å –≤ ROADMAP):**
```sql
CREATE TABLE quiz_sessions (
    id SERIAL PRIMARY KEY,
    user_id BIGINT REFERENCES users(user_id),
    category VARCHAR(64),  -- 'relationships', 'money', etc.
    status VARCHAR(32),    -- 'in_progress', 'completed', 'cancelled'
    current_question_index INT DEFAULT 0,
    total_questions INT,
    data JSONB,            -- Questions, answers, context
    results JSONB,         -- Analysis results
    created_at TIMESTAMP,
    completed_at TIMESTAMP
);
```

**Advantages:**
- JSONB –ø–æ–∑–≤–æ–ª—è–µ—Ç –≥–∏–±–∫–æ —Ö—Ä–∞–Ω–∏—Ç—å –≤–æ–ø—Ä–æ—Å—ã/–æ—Ç–≤–µ—Ç—ã
- –ù–µ –Ω—É–∂–Ω–æ schema migration –¥–ª—è –Ω–æ–≤—ã—Ö —Ç–∏–ø–æ–≤ –∫–≤–∏–∑–æ–≤

#### 3.3 Integration —Å Pattern Analysis

**–í–æ–ø—Ä–æ—Å:** –ö–∞–∫ –∫–≤–∏–∑-—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–Ω—Ç–µ–≥—Ä–∏—Ä—É—é—Ç—Å—è –≤ —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é —Å–∏—Å—Ç–µ–º—É?

**–í–∞—Ä–∏–∞–Ω—Ç—ã:**

**Option A: Quiz creates new patterns**
```python
# –ü–æ—Å–ª–µ –∫–≤–∏–∑–∞:
quiz_patterns = analyze_quiz_results(session)
# –î–æ–±–∞–≤–ª—è–µ–º –≤ user_profile.patterns –∫–∞–∫ –æ–±—ã—á–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
# Embeddings –º–æ–≥—É—Ç –º–µ—Ä–¥–∂–∏—Ç—å —Å conversational patterns
```

**Option B: Quiz creates separate insights**
```python
# –ö–≤–∏–∑-—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ö—Ä–∞–Ω—è—Ç—Å—è –æ—Ç–¥–µ–ª—å–Ω–æ:
user_profile.quiz_insights = {
  "relationships": {...},
  "money": {...}
}
# –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –≤ system prompt –∫–∞–∫ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Å–µ–∫—Ü–∏—è
```

**Recommendation:** Option A (creates patterns) ‚Äî –±–æ–ª–µ–µ —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–æ, embeddings –º–µ—Ä–¥–∂–∞—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏.

#### 3.4 Adaptive Quiz Logic

**Simple approach (MVP):**
```python
def generate_questions(user_id, category):
    profile = get_profile(user_id)
    base_questions = QUIZ_TEMPLATES[category]  # 10 –±–∞–∑–æ–≤—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤
    
    # –ê–¥–∞–ø—Ç–∞—Ü–∏—è based on profile
    if 'Imposter Syndrome' in profile.patterns:
        base_questions.append(IMPOSTER_SPECIFIC_QUESTIONS)
    
    return base_questions
```

**Advanced approach (V2):**
```python
def generate_next_question(session, previous_answer):
    # GPT –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–ª–µ–¥—É—é—â–∏–π –≤–æ–ø—Ä–æ—Å based on:
    # - Category
    # - User profile
    # - Previous answers
    
    prompt = f"""
    Generate next question for {session.category} quiz.
    User profile: {profile}
    Previous answers: {session.data['answers']}
    """
    return gpt.generate_question(prompt)
```

---

## üìã –ß–ï–ö–õ–ò–°–¢ –î–õ–Ø –°–õ–ï–î–£–Æ–©–ï–ì–û –ê–ì–ï–ù–¢–ê

### Immediate Actions (Day 1)

- [ ] –ü—Ä–æ—á–∏—Ç–∞—Ç—å –≤–µ—Å—å HANDOFF –¥–æ–∫—É–º–µ–Ω—Ç
- [ ] –ó–∞–ø—É—Å—Ç–∏—Ç—å smoke tests: `pytest tests/smoke_tests.py -v`
- [ ] –ó–∞–ø—É—Å—Ç–∏—Ç—å —Ç–µ—Å—Ç #4 (ultra_brief/formal/coach)
- [ ] –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ª–æ–≥–∏: `tail -f soul_test_bot_logs.txt | grep "QUICK\|MERGED"`
- [ ] –ü—Ä–æ–≤–µ—Ä–∏—Ç—å occurrences –≤ `/my_profile`

### Debugging Occurrences (Day 1-2)

- [ ] –ï—Å–ª–∏ occurrences < 5: –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–∏—á–∏–Ω—É (GPT, embeddings, frequency)
- [ ] –ü—Ä–∏–º–µ–Ω–∏—Ç—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π fix (—Å–º. "–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã")
- [ ] Retest –¥–æ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è occurrences ‚â• 5-8
- [ ] Update –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é —Å –Ω–∞–π–¥–µ–Ω–Ω—ã–º–∏ —Ä–µ—à–µ–Ω–∏—è–º–∏

### Code Review (Day 2-3)

- [ ] Review `pattern_analyzer.py` ‚Äî —Å–ª–æ–∂–Ω–æ—Å—Ç—å, –º–æ–∂–Ω–æ –ª–∏ —É–ø—Ä–æ—Å—Ç–∏—Ç—å?
- [ ] Review `openai_service.py` ‚Äî –ø—Ä–æ–º–ø—Ç—ã, –º–æ–∂–Ω–æ –ª–∏ –≤—ã–Ω–µ—Å—Ç–∏ –≤ templates?
- [ ] Check hardcoded strings ‚Äî –≤—ã–Ω–µ—Å—Ç–∏ –≤ config?
- [ ] Add unit tests –¥–ª—è –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π

### Stage 4 Planning (Day 3-4)

- [ ] –£—Ç–æ—á–Ω–∏—Ç—å requirements –¥–ª—è Dynamic Quiz —Å –∫–æ–º–∞–Ω–¥–æ–π
- [ ] –î–∏–∑–∞–π–Ω database schema (`quiz_sessions`)
- [ ] –î–∏–∑–∞–π–Ω API (`QuizService`, handlers)
- [ ] –†–µ—à–∏—Ç—å: –∫–∞–∫ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å –∫–≤–∏–∑-—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ profile?
- [ ] –ù–∞–ø–∏—Å–∞—Ç—å design doc –¥–ª—è Stage 4

### Implementation (Day 4+)

- [ ] Implement QuizSession model + repository
- [ ] Implement QuizService (generate_questions, evaluate_answers)
- [ ] Implement handlers (/quiz, FSM states)
- [ ] Integration —Å pattern_analyzer
- [ ] Testing

---

## üìö –ö–õ–Æ–ß–ï–í–´–ï –§–ê–ô–õ–´ –î–õ–Ø –ò–ó–£–ß–ï–ù–ò–Ø

### Core Logic (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –ø—Ä–æ—á–∏—Ç–∞—Ç—å)

1. **`bot/services/openai_service.py`** (~700 —Å—Ç—Ä–æ–∫)
   - –§—É–Ω–∫—Ü–∏—è: `build_system_prompt()` (—Å—Ç—Ä–æ–∫–∏ 36-260) ‚Äî –ö–ê–ö —Å—Ç—Ä–æ–∏—Ç—Å—è –ø—Ä–æ–º–ø—Ç
   - –§—É–Ω–∫—Ü–∏—è: `get_chat_completion()` (—Å—Ç—Ä–æ–∫–∏ 499-589) ‚Äî –æ—Å–Ω–æ–≤–Ω–æ–π flow
   - –§—É–Ω–∫—Ü–∏—è: `_enforce_message_length()` (—Å—Ç—Ä–æ–∫–∏ 469-492) ‚Äî post-processing

2. **`bot/services/pattern_analyzer.py`** (~600 —Å—Ç—Ä–æ–∫)
   - –§—É–Ω–∫—Ü–∏—è: `analyze_if_needed()` (—Å—Ç—Ä–æ–∫–∏ 580-594) ‚Äî —Ç—Ä–∏–≥–≥–µ—Ä—ã
   - –§—É–Ω–∫—Ü–∏—è: `quick_analysis()` (—Å—Ç—Ä–æ–∫–∏ 34-93) ‚Äî –æ—Å–Ω–æ–≤–Ω–æ–π –∞–Ω–∞–ª–∏–∑
   - –§—É–Ω–∫—Ü–∏—è: `_analyze_conversation_quick()` (—Å—Ç—Ä–æ–∫–∏ 95-195) ‚Äî –ø—Ä–æ–º–ø—Ç –¥–ª—è GPT
   - –§—É–Ω–∫—Ü–∏—è: `_add_patterns_with_dedup()` (—Å—Ç—Ä–æ–∫–∏ 366-425) ‚Äî –º–µ—Ä–¥–∂ –ª–æ–≥–∏–∫–∞

3. **`bot/services/embedding_service.py`** (~150 —Å—Ç—Ä–æ–∫)
   - –§—É–Ω–∫—Ü–∏—è: `get_embedding()` (—Å—Ç—Ä–æ–∫–∏ 32-42)
   - –§—É–Ω–∫—Ü–∏—è: `cosine_similarity()` (—Å—Ç—Ä–æ–∫–∏ 45-55)
   - –§—É–Ω–∫—Ü–∏—è: `is_duplicate()` (—Å—Ç—Ä–æ–∫–∏ 180-200)

### Data Layer

4. **`database/models/user_profile.py`** (~100 —Å—Ç—Ä–æ–∫)
   - –°—Ö–µ–º–∞ –¥–∞–Ω–Ω—ã—Ö: patterns, insights, emotional_state

5. **`database/repository/user_profile.py`** (~150 —Å—Ç—Ä–æ–∫)
   - CRUD –æ–ø–µ—Ä–∞—Ü–∏–∏ –¥–ª—è user_profile

### UI/Handlers

6. **`bot/handlers/user/profile.py`** (~400 —Å—Ç—Ä–æ–∫)
   - Style settings handlers
   - `/my_profile` command (—Å—Ç—Ä–æ–∫–∏ 250-350)

### Tests

7. **`tests/smoke_tests.py`** (~500 —Å—Ç—Ä–æ–∫)
   - `TestLevel2ContextualExamples` (—Å—Ç—Ä–æ–∫–∏ 385-483)

---

## üîó –ü–û–õ–ï–ó–ù–´–ï –î–û–ö–£–ú–ï–ù–¢–´

1. **`IMPLEMENTATION_ROADMAP.md`** ‚Äî –æ–±—â–∏–π roadmap –ø—Ä–æ–µ–∫—Ç–∞
2. **`LEVEL2_TEST_RESULTS_ANALYSIS.md`** ‚Äî –∞–Ω–∞–ª–∏–∑ –ø—Ä–æ–±–ª–µ–º –∏–∑ —Ç–µ—Å—Ç–æ–≤
3. **`LEVEL2_FIXES_ROUND2.md`** ‚Äî –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Ñ–∏–∫—Å—ã (occurrences)
4. **`AGENT_TEST_INSTRUCTIONS_V2.md`** ‚Äî –∫–∞–∫ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å —Å –∞–≥–µ–Ω—Ç–æ–º
5. **`LEVEL2_QUOTE_FIX.md`** ‚Äî –¥–µ—Ç–∞–ª–∏ Quote Hallucination fix

---

## üí° –§–ò–õ–û–°–û–§–ò–Ø –ö–û–î–ê

### –ü—Ä–∏–Ω—Ü–∏–ø—ã, –∫–æ—Ç–æ—Ä—ã–º —Å–ª–µ–¥–æ–≤–∞–ª–∏:

1. **Hybrid Approach:** MVP —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å + scalable architecture
   - –°–Ω–∞—á–∞–ª–∞ —Ä–µ–∞–ª–∏–∑—É–µ–º –ø—Ä–æ—Å—Ç–æ (GPT analysis)
   - –ù–æ —Å—Ç—Ä–æ–∏–º –ø—Ä–∞–≤–∏–ª—å–Ω—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É (embeddings, dedup)
   - –õ–µ–≥–∫–æ —Ä–∞—Å—à–∏—Ä—è—Ç—å –≤ –±—É–¥—É—â–µ–º

2. **Feature Flags:** –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –º–∏–≥—Ä–∞—Ü–∏—è
   ```python
   if is_feature_enabled('ENABLE_PATTERN_ANALYSIS'):
       await pattern_analyzer.analyze_if_needed(user_id)
   ```

3. **JSONB everywhere:** –ì–∏–±–∫–æ—Å—Ç—å –±–µ–∑ migrations
   - Patterns, insights, emotional_state ‚Äî –≤—Å—ë JSONB
   - –ú–æ–∂–Ω–æ –º–µ–Ω—è—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É –±–µ–∑ ALTER TABLE

4. **Logging first:** Debugging-friendly
   - –û–±–∏–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö –º–µ—Å—Ç–∞—Ö
   - –õ–µ–≥–∫–æ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–±–ª–µ–º—ã

5. **Incremental testing:** Smoke tests –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ —ç—Ç–∞–ø–∞
   - –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ –Ω–∏—á–µ–≥–æ –Ω–µ —Å–ª–æ–º–∞–ª–æ—Å—å
   - –ë—ã—Å—Ç—Ä—ã–π feedback loop

---

## üéì LESSONS LEARNED

### –ß—Ç–æ —Å—Ä–∞–±–æ—Ç–∞–ª–æ —Ö–æ—Ä–æ—à–æ:

1. ‚úÖ **Quote Fix —á–µ—Ä–µ–∑ "RECENT MESSAGES"** ‚Äî 100% accuracy —Å—Ä–∞–∑—É
2. ‚úÖ **Embeddings –¥–ª—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏** ‚Äî —Ä–∞–±–æ—Ç–∞–µ—Ç, –Ω–æ –Ω—É–∂–µ–Ω tuning (threshold)
3. ‚úÖ **JSONB –¥–ª—è –≥–∏–±–∫–æ—Å—Ç–∏** ‚Äî –ª–µ–≥–∫–æ –º–µ–Ω—è—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö
4. ‚úÖ **Incremental approach** ‚Äî Stage by Stage, smoke tests
5. ‚úÖ **Detailed logging** ‚Äî –ø–æ–º–æ–≥–ª–æ –Ω–∞–π—Ç–∏ –±–∞–≥ (SKIP vs CREATE AGAIN)

### –ß—Ç–æ –±—ã–ª–æ —Å–ª–æ–∂–Ω–æ:

1. ‚ö†Ô∏è **Occurrences growth** ‚Äî –¥–æ —Å–∏—Ö –ø–æ—Ä –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –∏–¥–µ–∞–ª—å–Ω–æ
2. ‚ö†Ô∏è **GPT prompt engineering** ‚Äî –Ω—É–∂–Ω–æ –º–Ω–æ–≥–æ –∏—Ç–µ—Ä–∞—Ü–∏–π
3. ‚ö†Ô∏è **Embeddings tuning** ‚Äî threshold 0.55 –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ optimal
4. ‚ö†Ô∏è **System prompt length** ‚Äî –Ω—É–∂–Ω–æ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞—Ç—å detail vs tokens

### –ß—Ç–æ –±—ã —Å–¥–µ–ª–∞–ª–∏ –ø–æ-–¥—Ä—É–≥–æ–º—É:

1. üîÑ **–†–∞–Ω—å—à–µ –¥–æ–±–∞–≤–∏—Ç—å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ** ‚Äî –ø–æ—Ç–µ—Ä—è–ª–∏ –≤—Ä–µ–º—è –Ω–∞ debugging
2. üîÑ **Unit tests —Å —Å–∞–º–æ–≥–æ –Ω–∞—á–∞–ª–∞** ‚Äî —Å–µ–π—á–∞—Å —Å–ª–æ–∂–Ω–æ –¥–æ–±–∞–≤–ª—è—Ç—å
3. üîÑ **Template system –¥–ª—è –ø—Ä–æ–º–ø—Ç–æ–≤** ‚Äî —Å–µ–π—á–∞—Å hardcoded –≤ –∫–æ–¥–µ
4. üîÑ **Vector DB —Å —Å–∞–º–æ–≥–æ –Ω–∞—á–∞–ª–∞** ‚Äî –µ—Å–ª–∏ embeddings –º–∞—Å—à—Ç–∞–±–∏—Ä—É—é—Ç—Å—è

---

## üöÄ –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï

**–¢–µ–∫—É—â–∏–π —Å—Ç–∞—Ç—É—Å:** Level 2 –ø–æ—á—Ç–∏ –∑–∞–≤–µ—Ä—à—ë–Ω (90%)

**–ß—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç –æ—Ç–ª–∏—á–Ω–æ:**
- ‚úÖ Quote accuracy (100%)
- ‚úÖ Pattern detection (–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è)
- ‚úÖ Style settings (brief, formal, coach)
- ‚úÖ Evidence integration (GPT –≤–∏–¥–∏—Ç —Ü–∏—Ç–∞—Ç—ã)

**–ß—Ç–æ –Ω—É–∂–Ω–æ –¥–æ—Ä–∞–±–æ—Ç–∞—Ç—å:**
- ‚è≥ Occurrences growth (—Ç–µ–∫—É—â–∞—è –∑–∞–¥–∞—á–∞ #1)

**–ß—Ç–æ –¥–∞–ª—å—à–µ:**
- Stage 4: Dynamic Quiz
- Performance optimization
- Code refactoring

**–£–¥–∞—á–∏, —Å–ª–µ–¥—É—é—â–∏–π –∞–≥–µ–Ω—Ç! –ö–æ–¥ –≤ —Ö–æ—Ä–æ—à–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏, –æ—Å—Ç–∞–ª–æ—Å—å —Ç–æ–ª—å–∫–æ debug'–Ω—É—Ç—å occurrences –∏ –º–æ–∂–Ω–æ –ø–µ—Ä–µ—Ö–æ–¥–∏—Ç—å –∫ –∫–≤–∏–∑–∞–º.** üéØ

---

**–î–∞—Ç–∞:** 29 –æ–∫—Ç—è–±—Ä—è 2025  
**–ê–≤—Ç–æ—Ä:** AI Agent (Claude Sonnet 4.5)  
**–î–ª—è –≤–æ–ø—Ä–æ—Å–æ–≤:** –°–º. git history, –≤—Å–µ commits —Å detailed messages

