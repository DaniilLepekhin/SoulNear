"""
Adaptive Quiz Service - Pattern-Based Adaptation

Analyzes user answers mid-quiz to detect emerging patterns
and generates follow-up questions for deeper exploration.

Strategy:
1. Quick analysis after question 5 (midpoint)
2. If strong patterns detected (confidence > 0.7) ‚Üí generate 2-3 follow-ups
3. Continue with remaining base questions
4. Final comprehensive analysis at quiz completion

Author: AI Agent
Created: 2025-10-30
"""

import logging
from typing import Optional

from bot.services.ai.gpt_service import GPTService
from database.models.quiz_session import QuizSession


logger = logging.getLogger(__name__)


class AdaptiveQuizService:
    """
    Handles adaptive quiz logic: pattern detection and follow-up question generation.
    """
    
    # Thresholds for adaptive behavior
    BRANCH_AFTER_QUESTION = 5  # Trigger analysis after Q5
    CONFIDENCE_THRESHOLD = 0.7  # Minimum confidence to generate follow-ups
    GENERATE_CANDIDATE_QUESTIONS = 5  # üî• Generate 5 candidates
    SELECT_TOP_QUESTIONS = 3  # üî• Select top 2-3 from candidates
    MAX_TOTAL_FOLLOWUPS = 3  # üî• Maximum 3 follow-ups (was 5)
    
    def __init__(self, gpt_service: GPTService):
        self.gpt = gpt_service
    
    async def should_branch(self, session: QuizSession) -> bool:
        """
        Determine if we should add follow-up questions based on current progress.
        
        Args:
            session: Current quiz session
            
        Returns:
            True if adaptive branching should occur
        """
        # Only branch once at midpoint
        if session.current_question_index != self.BRANCH_AFTER_QUESTION:
            return False
        
        # Don't branch if we already have follow-ups
        if len(session.questions) > session.total_questions:
            logger.info("Already branched, skipping")
            return False
        
        # Need at least 3 answers to analyze
        if len(session.answers) < 3:
            logger.warning("Not enough answers for branching")
            return False
        
        return True
    
    async def analyze_patterns(self, session: QuizSession) -> list[dict]:
        """
        Quick pattern analysis of answers so far.
        
        Args:
            session: Quiz session with answers
            
        Returns:
            List of detected patterns with confidence scores
        """
        # Prepare context from answers
        answers_text = self._format_answers_for_analysis(session)
        
        prompt = f"""
–†–∞–∑–±–µ—Ä–∏ –æ—Ç–≤–µ—Ç—ã –∫–≤–∏–∑–∞ –∏ –æ–ø–∏—à–∏, –∫–∞–∫–∏–µ —Å–∫—Ä—ã—Ç—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –ø—Ä–æ—Å—Ç—É–ø–∞—é—Ç. –ü–∏—à–∏ —Ç–æ–ª—å–∫–æ –ø–æ-—Ä—É—Å—Å–∫–∏.

–ö–∞—Ç–µ–≥–æ—Ä–∏—è: {session.category}
–û—Ç–≤–µ—Ç—ã –Ω–∞ —Å–µ–π—á–∞—Å:
{answers_text}

–ó–∞–¥–∞—á–∞:
1. –ù–∞–π–¥–∏ 1‚Äì3 –ø–∞—Ç—Ç–µ—Ä–Ω–∞ (–µ—Å–ª–∏ –º–µ–Ω—å—à–µ ‚Äî –Ω–∏—á–µ–≥–æ —Å—Ç—Ä–∞—à–Ω–æ–≥–æ).
2. –î–ª—è –∫–∞–∂–¥–æ–≥–æ –¥–∞–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (0.0‚Äì1.0) –∏ –∫–æ—Ä–æ—Ç–∫–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ.
3. –ü—Ä–∏–≤–µ–¥–∏ –¥–≤–µ —Ç–æ—á–Ω—ã–µ —Ü–∏—Ç–∞—Ç—ã –∏–∑ –æ—Ç–≤–µ—Ç–æ–≤ –≤ –∫–∞—á–µ—Å—Ç–≤–µ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞.

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ (JSON –º–∞—Å—Å–∏–≤):
[
  {{
    "title": "–ö–æ—Ä–æ—Ç–∫–æ–µ —Ä—É—Å—Å–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ",
    "title_ru": "–¢–æ –∂–µ –Ω–∞–∑–≤–∞–Ω–∏–µ (–Ω–∞ —Ä—É—Å—Å–∫–æ–º)",
    "confidence": 0.85,
    "evidence": ["–¶–∏—Ç–∞—Ç–∞ 1", "–¶–∏—Ç–∞—Ç–∞ 2"],
    "description": "–ü–∞—Ä–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, —á—Ç–æ —ç—Ç–æ –∑–Ω–∞—á–∏—Ç (–ø–æ-—Ä—É—Å—Å–∫–∏)"
  }}
]

–£–ø–æ—Ä –Ω–∞ –ø–∞—Ç—Ç–µ—Ä–Ω—ã, —É –∫–æ—Ç–æ—Ä—ã—Ö –µ—Å—Ç—å —á—ë—Ç–∫–∏–µ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è –∏–ª–∏ –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è —Ä–µ–∞–∫—Ü–∏–∏."""

        try:
            response = await self.gpt.generate_completion(
                messages=[{"role": "user", "content": prompt}],
                model="gpt-4o-mini",
                temperature=0.3,
                json_mode=True
            )
            
            patterns = self._parse_patterns_response(response)
            logger.info(f"Quick analysis found {len(patterns)} patterns")
            
            return patterns
            
        except Exception as e:
            logger.error(f"Pattern analysis failed: {e}")
            return []
    
    async def generate_followup_questions(
        self,
        pattern: dict,
        session: QuizSession
    ) -> list[dict]:
        """
        Generate follow-up questions to explore a detected pattern deeper.
        
        Args:
            pattern: Detected pattern dict
            session: Quiz session context
            
        Returns:
            List of follow-up questions in standard format
        """
        category = session.category
        pattern_title = pattern.get('title_ru', pattern.get('title'))
        evidence = pattern.get('evidence', [])
        
        # ‚úÖ FIX: Escape JSON braces in f-string to avoid ValueError
        prompt = f"""–¢—ã ‚Äî Soul Near. –ü—Ä–∏–¥—É–º–∞–π –≤–æ–ø—Ä–æ—Å—ã, –∫–æ—Ç–æ—Ä—ã–µ —Ä–∞—Å–∫—Ä–æ—é—Ç –≥–ª—É–±–∏–Ω—É –ø–∞—Ç—Ç–µ—Ä–Ω–∞ –∏ –ø–æ–¥—Ç–æ–ª–∫–Ω—É—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —É–≤–∏–¥–µ—Ç—å —Ç–æ, —á—Ç–æ –æ–Ω —É–ø—É—Å–∫–∞–µ—Ç.

–ö–æ–Ω—Ç–µ–∫—Å—Ç:
- –ü–∞—Ç—Ç–µ—Ä–Ω: {pattern_title}
- –¶–∏—Ç–∞—Ç—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {', '.join(evidence[:2])}
- –ö–∞—Ç–µ–≥–æ—Ä–∏—è –∫–≤–∏–∑–∞: {category}

–ó–∞–¥–∞—á–∞: —Å–≥–µ–Ω–µ—Ä–∏—Ä—É–π {self.GENERATE_CANDIDATE_QUESTIONS} –∫–∞–Ω–¥–∏–¥–∞—Ç–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤, —á—Ç–æ–±—ã:
1. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –∫–∞–∫ –ø—Ä–æ—è–≤–ª—è–µ—Ç—Å—è –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–µ –º–µ–∂–¥—É —Å–ª–æ–≤–∞–º–∏ –∏ –¥–µ–π—Å—Ç–≤–∏—è–º–∏.
2. –ü–æ–∫–∞–∑–∞—Ç—å —Å–∫—Ä—ã—Ç—É—é –¥–∏–Ω–∞–º–∏–∫—É/—Å—Ç—Ä–∞—Ö, –∫–æ—Ç–æ—Ä—ã–π –¥–µ—Ä–∂–∏—Ç –ø–∞—Ç—Ç–µ—Ä–Ω –∂–∏–≤—ã–º.
3. –ù–∞–π—Ç–∏ —Ä–µ—Å—É—Ä—Å, –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–Ω–æ —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—å –≤ –¥–µ–π—Å—Ç–≤–∏–µ.

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
‚Ä¢ –†—É—Å—Å–∫–∏–π —è–∑—ã–∫, –∂–∏–≤–æ–π —Ç–æ–Ω Soul Near (—á–µ—Å—Ç–Ω–æ, —Ç–æ—á–Ω–æ, –±–µ–∑ –∫–ª–∏—à–µ).
‚Ä¢ –ò—Å–ø–æ–ª—å–∑—É–π —Ä–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã: —à–∫–∞–ª–∞ 1‚Äì5, –≤—ã–±–æ—Ä, –æ—Ç–∫—Ä—ã—Ç—ã–π –≤–æ–ø—Ä–æ—Å (–Ω–µ –±–æ–ª—å—à–µ –¥–≤—É—Ö –æ—Ç–∫—Ä—ã—Ç—ã—Ö).
‚Ä¢ –î–ª—è —à–∫–∞–ª—ã –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –æ–ø—Ü–∏–∏ ["–ù–∏–∫–æ–≥–¥–∞", "–†–µ–¥–∫–æ", "–ò–Ω–æ–≥–¥–∞", "–ß–∞—Å—Ç–æ", "–ü–æ—Å—Ç–æ—è–Ω–Ω–æ"].
‚Ä¢ –ú–æ–∂–µ—à—å –¥–æ–±–∞–≤–∏—Ç—å –∫–æ—Ä–æ—Ç–∫–∏–π –ø—Ä–µ—Ñ–µ–π—Å (–¥–æ 80 —Å–∏–º–≤–æ–ª–æ–≤) –≤ –ø–æ–ª–µ "preface", –µ—Å–ª–∏ –Ω—É–∂–Ω–æ –∑–∞–¥–∞—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏–µ.
‚Ä¢ –ú–∏–Ω–∏–º—É–º –æ–¥–∏–Ω –≤–æ–ø—Ä–æ—Å –¥–æ–ª–∂–µ–Ω –≤—Å–∫—Ä—ã–≤–∞—Ç—å –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–µ, –æ–¥–∏–Ω ‚Äî —Å–∫—Ä—ã—Ç—É—é –¥–∏–Ω–∞–º–∏–∫—É, –æ–¥–∏–Ω ‚Äî –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ—Å—É—Ä—Å. –ü–æ–º–µ—á–∞–π —ç—Ç–æ –≤ –ø–æ–ª–µ insight_focus.
‚Ä¢ –£ –∫–∞–∂–¥–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –ø–æ–ª—è:
  - "insight_focus": "contradiction" | "hidden_dynamic" | "resource_shift"
  - "why_it_matters": –¥–æ 120 —Å–∏–º–≤–æ–ª–æ–≤, –∑–∞—á–µ–º –∏–º–µ–Ω–Ω–æ —ç—Ç–æ—Ç –≤–æ–ø—Ä–æ—Å.
‚Ä¢ –ù–µ –ø–æ–≤—Ç–æ—Ä—è–π—Å—è, –∏–∑–±–µ–≥–∞–π –æ–±—â–∏—Ö —Ñ—Ä–∞–∑ "—á—Ç–æ —Ç—ã —á—É–≤—Å—Ç–≤—É–µ—à—å?" ‚Äî –∫–æ–Ω–∫—Ä–µ—Ç–∏–∫–∞ –∏ —Ç–æ—á–Ω–æ—Å—Ç—å.
‚Ä¢ –û—Ç—Å–æ—Ä—Ç–∏—Ä—É–π –≤–æ–ø—Ä–æ—Å—ã –ø–æ —Å–∏–ª–µ –∏–Ω—Å–∞–π—Ç–∞, –¥–æ–±–∞–≤—å –ø–æ–ª–µ "quality_score" (0.0‚Äì1.0).

–í–æ–∑–≤—Ä–∞—â–∞–π JSON:
{{{{
  "questions": [
    {{{{
      "type": "scale",
      "text": "–ù–∞—Å–∫–æ–ª—å–∫–æ —á–∞—Å—Ç–æ —Ç—ã ‚Ä¶?",
      "options": ["–ù–∏–∫–æ–≥–¥–∞", "–†–µ–¥–∫–æ", "–ò–Ω–æ–≥–¥–∞", "–ß–∞—Å—Ç–æ", "–ü–æ—Å—Ç–æ—è–Ω–Ω–æ"],
      "related_pattern": "{pattern_title}",
      "insight_focus": "contradiction",
      "why_it_matters": "–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –∫–∞–∫ —á–∞—Å—Ç–æ —á–µ–ª–æ–≤–µ–∫ –≤—ã–±–∏—Ä–∞–µ—Ç –±—Ä–æ–Ω—é –≤–º–µ—Å—Ç–æ —à–∞–≥–∞.",
      "quality_score": 0.95
    }}}}
  ]
}}}}
"""

        try:
            response = await self.gpt.generate_completion(
                messages=[{"role": "user", "content": prompt}],
                model="gpt-4o-mini",
                temperature=0.5,
                json_mode=True
            )
            
            all_questions = self._parse_questions_response(response)
            logger.info(f"Generated {len(all_questions)} candidate questions for {pattern_title}")
            
            # üî• SELECT TOP QUESTIONS: Sort by quality_score and take top N
            if all_questions:
                # Sort by quality_score (descending)
                sorted_questions = sorted(
                    all_questions,
                    key=lambda q: q.get('quality_score', 0.5),
                    reverse=True
                )
                
                # Select top questions (2-3)
                top_count = min(self.SELECT_TOP_QUESTIONS, len(sorted_questions))
                questions = sorted_questions[:top_count]
                
                logger.info(
                    f"Selected top {len(questions)}/{len(all_questions)} questions "
                    f"(scores: {[q.get('quality_score', 0) for q in questions]})"
                )
            else:
                questions = []
            
            # Normalize and mark as adaptive questions
            for q in questions:
                # üîß FIX: Normalize question format (convert scale_labels to options)
                q = self._normalize_question_format(q)
                
                q['is_adaptive'] = True
                q['trigger_pattern'] = pattern_title
                # Remove quality_score from final output (internal use only)
                q.pop('quality_score', None)
                q.pop('reasoning', None)
            
            return questions
            
        except Exception as e:
            logger.error(f"Follow-up generation failed: {e}")
            return []
    
    async def get_adaptive_questions(self, session: QuizSession) -> list[dict]:
        """
        Main method: analyze patterns and generate all follow-up questions.
        
        Args:
            session: Current quiz session
            
        Returns:
            List of adaptive follow-up questions to insert
        """
        # Analyze patterns
        patterns = await self.analyze_patterns(session)
        
        if not patterns:
            logger.info("No patterns detected for adaptive branching")
            return []
        
        # Filter patterns by confidence
        strong_patterns = [
            p for p in patterns
            if p.get('confidence', 0) >= self.CONFIDENCE_THRESHOLD
        ]
        
        if not strong_patterns:
            logger.info("No high-confidence patterns for branching")
            return []
        
        logger.info(f"Found {len(strong_patterns)} strong patterns")
        
        # Generate follow-ups for top 1 pattern only (focused approach)
        all_followups = []
        
        # üî• UPGRADE: Focus on strongest pattern only
        if strong_patterns:
            top_pattern = strong_patterns[0]
            logger.info(f"Focusing on strongest pattern: {top_pattern.get('title_ru', top_pattern.get('title'))} (confidence: {top_pattern.get('confidence')})")
            
            followups = await self.generate_followup_questions(top_pattern, session)
            all_followups.extend(followups)
        
        # Limit total follow-ups (should be 2-3 already, but ensure)
        all_followups = all_followups[:self.MAX_TOTAL_FOLLOWUPS]
        
        logger.info(f"Generated {len(all_followups)} total follow-up questions")
        
        return all_followups
    
    def _format_answers_for_analysis(self, session: QuizSession) -> str:
        """Format answers into readable text for GPT analysis."""
        lines = []
        
        for i, (question, answer) in enumerate(zip(session.questions, session.answers), 1):
            q_text = question.get('text', '')
            a_value = answer.get('value', '')
            
            # For scale questions, include the actual value
            if question.get('type') == 'scale':
                scale_min = question.get('scale_labels', {}).get('min', '')
                scale_max = question.get('scale_labels', {}).get('max', '')
                lines.append(f"Q{i}: {q_text}\nA{i}: {a_value}/5 ({scale_min}...{scale_max})")
            
            # For choice questions
            elif question.get('type') == 'choice':
                lines.append(f"Q{i}: {q_text}\nA{i}: {a_value}")
            
            # For text questions
            else:
                lines.append(f"Q{i}: {q_text}\nA{i}: {a_value}")
        
        return "\n\n".join(lines)
    
    def _parse_patterns_response(self, response: str) -> list[dict]:
        """Parse GPT response into pattern objects."""
        import json
        
        try:
            # Try to parse as JSON
            data = json.loads(response)
            
            # Handle both formats: direct list or {"patterns": [...]}
            if isinstance(data, dict) and 'patterns' in data:
                patterns = data['patterns']
            elif isinstance(data, list):
                patterns = data
            else:
                logger.warning("Response is not a list or dict with 'patterns', wrapping")
                patterns = [data]
            
            # Validate structure
            valid_patterns = []
            for p in patterns:
                if isinstance(p, dict) and 'title' in p and 'confidence' in p:
                    valid_patterns.append(p)
                else:
                    logger.warning(f"Invalid pattern structure: {p}")
            
            return valid_patterns
            
        except json.JSONDecodeError as e:
            logger.error(f"JSON parse error: {e}")
            return []
    
    def _parse_questions_response(self, response: str) -> list[dict]:
        """Parse GPT response into question objects."""
        import json
        
        try:
            data = json.loads(response)
            
            # Handle both formats: direct list or {"questions": [...]}
            if isinstance(data, dict) and 'questions' in data:
                questions = data['questions']
            elif isinstance(data, list):
                questions = data
            else:
                logger.warning("Response is not a list or dict with 'questions', wrapping")
                questions = [data]
            
            # Validate structure
            valid_questions = []
            for q in questions:
                if isinstance(q, dict) and 'type' in q and 'text' in q:
                    valid_questions.append(q)
                else:
                    logger.warning(f"Invalid question structure: {q}")
            
            return valid_questions
            
        except json.JSONDecodeError as e:
            logger.error(f"JSON parse error: {e}")
            return []
    
    def _normalize_question_format(self, question: dict) -> dict:
        """
        Normalize question format to ensure compatibility with quiz handlers.
        
        Converts scale_labels to options if needed, ensures all required fields exist.
        
        Args:
            question: Raw question dict from GPT
            
        Returns:
            Normalized question dict
        """
        # Convert scale_labels to options (legacy format fix)
        if 'scale_labels' in question and 'options' not in question:
            logger.info("Converting scale_labels to options")
            question['options'] = ["–ù–∏–∫–æ–≥–¥–∞", "–†–µ–¥–∫–æ", "–ò–Ω–æ–≥–¥–∞", "–ß–∞—Å—Ç–æ", "–ü–æ—Å—Ç–æ—è–Ω–Ω–æ"]
            question.pop('scale_labels', None)
        
        # Ensure options exist for scale/choice questions
        if question.get('type') in ['scale', 'multiple_choice', 'choice']:
            if 'options' not in question or not question['options']:
                # Fallback options
                if question.get('type') == 'scale':
                    question['options'] = ["–ù–∏–∫–æ–≥–¥–∞", "–†–µ–¥–∫–æ", "–ò–Ω–æ–≥–¥–∞", "–ß–∞—Å—Ç–æ", "–ü–æ—Å—Ç–æ—è–Ω–Ω–æ"]
                else:
                    question['options'] = ["–î–∞", "–ù–µ—Ç", "–ù–µ –∑–Ω–∞—é"]
                logger.warning(f"Added fallback options for question: {question.get('text', 'unknown')[:50]}")
        
        # Normalize type naming (choice vs multiple_choice)
        if question.get('type') == 'choice':
            question['type'] = 'multiple_choice'
        
        # Add missing id if needed
        if 'id' not in question:
            import uuid
            question['id'] = f"adaptive_{uuid.uuid4().hex[:8]}"
        
        return question

