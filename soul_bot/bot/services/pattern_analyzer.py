"""
üß† Pattern Analyzer Service - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

–û—Å–Ω–æ–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏:
1. Quick Analysis (–ø–æ—Å–ª–µ 5 —Å–æ–æ–±—â–µ–Ω–∏–π) - –ø–∞—Ç—Ç–µ—Ä–Ω—ã + mood
2. Deep Analysis (–ø–æ—Å–ª–µ 20 —Å–æ–æ–±—â–µ–Ω–∏–π) - –∏–Ω—Å–∞–π—Ç—ã + recommendations
3. –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è —á–µ—Ä–µ–∑ embeddings
4. Learning loop (—á—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç/–Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç)

Architecture: Moderate + Embeddings
"""
import logging
import uuid
from datetime import datetime, timedelta
from typing import Optional
import json

from openai import AsyncOpenAI

from config import OPENAI_API_KEY, is_feature_enabled
from bot.services import embedding_service
from database.repository import user_profile, conversation_history
import database.repository.user as db_user

logger = logging.getLogger(__name__)

client = AsyncOpenAI(api_key=OPENAI_API_KEY)


# ==========================================
# üéØ QUICK ANALYSIS (–∫–∞–∂–¥—ã–µ 5 —Å–æ–æ–±—â–µ–Ω–∏–π)
# ==========================================

async def quick_analysis(user_id: int, assistant_type: str = 'helper'):
    """
    –ë—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 5-10 —Å–æ–æ–±—â–µ–Ω–∏–π
    
    –í—ã—è–≤–ª—è–µ—Ç:
    - 1-2 –Ω–æ–≤—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å)
    - –¢–µ–∫—É—â–µ–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ (mood)
    - –£—Ä–æ–≤–µ–Ω—å —Å—Ç—Ä–µ—Å—Å–∞/—ç–Ω–µ—Ä–≥–∏–∏
    
    Args:
        user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        assistant_type: –¢–∏–ø –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
    """
    if not is_feature_enabled('ENABLE_PATTERN_ANALYSIS'):
        return
    
    try:
        logger.info(f"Quick analysis for user {user_id}")
        
        # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 10 —Å–æ–æ–±—â–µ–Ω–∏–π
        messages = await conversation_history.get_context(
            user_id=user_id,
            assistant_type=assistant_type,
            max_messages=10
        )
        
        if len(messages) < 4:
            logger.debug("Not enough messages for analysis")
            return
        
        # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–π –ø—Ä–æ—Ñ–∏–ª—å
        profile = await user_profile.get_or_create(user_id)
        existing_patterns = profile.patterns.get('patterns', [])
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —á–µ—Ä–µ–∑ GPT-4
        analysis = await _analyze_conversation_quick(messages, existing_patterns)
        
        if not analysis:
            return
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã (—Å –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–µ–π)
        if analysis.get('new_patterns'):
            await _add_patterns_with_dedup(user_id, analysis['new_patterns'], existing_patterns)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º emotional state
        if analysis.get('mood'):
            await _update_emotional_state(user_id, analysis['mood'])
        
        logger.info(f"Quick analysis complete: {len(analysis.get('new_patterns', []))} patterns, mood={analysis.get('mood', {}).get('current_mood')}")
        
    except Exception as e:
        logger.error(f"Quick analysis failed: {e}")


async def _analyze_conversation_quick(
    messages: list[dict],
    existing_patterns: list[dict]
) -> Optional[dict]:
    """
    GPT-4 –∞–Ω–∞–ª–∏–∑ –¥–∏–∞–ª–æ–≥–∞ (quick version)
    """
    # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞
    conversation_text = "\n".join([
        f"{msg['role']}: {msg['content']}" 
        for msg in messages[-10:]
    ])
    
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä existing patterns (GPT-4 –∫–æ–Ω—Ç–µ–∫—Å—Ç)
    existing_summaries = [
        f"- {p['title']}" 
        for p in existing_patterns[:10]
    ]
    
    prompt = f"""
Analyze this conversation and extract behavioral/emotional patterns.

CONVERSATION (last 10 messages):
{conversation_text}

EXISTING PATTERNS (don't duplicate these):
{chr(10).join(existing_summaries) if existing_summaries else 'None yet'}

Tasks:
1. Find 1-2 NEW behavioral or emotional patterns (if any significant ones exist)
2. Detect current mood and energy level
3. DON'T duplicate existing patterns

Return JSON:
{{
  "new_patterns": [
    {{
      "type": "behavioral|emotional|cognitive",
      "title": "Short title (5-7 words)",
      "description": "Detailed description",
      "evidence": ["quote from conversation", "another quote"],
      "tags": ["tag1", "tag2"],
      "frequency": "high|medium|low",
      "confidence": 0.0-1.0
    }}
  ],
  "mood": {{
    "current_mood": "slightly_down|neutral|good|energetic|stressed",
    "stress_level": "low|medium|high",
    "energy_level": "low|medium|high",
    "triggers": ["trigger1", "trigger2"]
  }}
}}

IMPORTANT: If no new significant patterns found, return empty new_patterns array.
"""
    
    try:
        response = await client.chat.completions.create(
            model="gpt-4o-mini",  # –î–µ—à–µ–≤–ª–µ –¥–ª—è quick analysis
            messages=[
                {"role": "system", "content": "You are an expert psychologist analyzing conversation patterns."},
                {"role": "user", "content": prompt}
            ],
            response_format={"type": "json_object"},
            temperature=0.3
        )
        
        result = json.loads(response.choices[0].message.content)
        return result
        
    except Exception as e:
        logger.error(f"GPT-4 analysis failed: {e}")
        return None


# ==========================================
# üîç DEEP ANALYSIS (–∫–∞–∂–¥—ã–µ 20 —Å–æ–æ–±—â–µ–Ω–∏–π)
# ==========================================

async def deep_analysis(user_id: int, assistant_type: str = 'helper'):
    """
    –ì–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–Ω—Å–∞–π—Ç–æ–≤
    
    –í—ã—è–≤–ª—è–µ—Ç:
    - –°–≤—è–∑–∏ –º–µ–∂–¥—É –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º–∏
    - –î–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã–µ —Ç—Ä–µ–Ω–¥—ã
    - –ò–Ω—Å–∞–π—Ç—ã —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏
    - –û–±–Ω–æ–≤–ª—è–µ—Ç learning preferences
    
    Args:
        user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        assistant_type: –¢–∏–ø –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
    """
    if not is_feature_enabled('ENABLE_PATTERN_ANALYSIS'):
        return
    
    try:
        logger.info(f"Deep analysis for user {user_id}")
        
        # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 30 —Å–æ–æ–±—â–µ–Ω–∏–π
        messages = await conversation_history.get_context(
            user_id=user_id,
            assistant_type=assistant_type,
            max_messages=30
        )
        
        if len(messages) < 10:
            logger.debug("Not enough messages for deep analysis")
            return
        
        # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–π –ø—Ä–æ—Ñ–∏–ª—å
        profile = await user_profile.get_or_create(user_id)
        existing_patterns = profile.patterns.get('patterns', [])
        existing_insights = profile.insights.get('insights', [])
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —á–µ—Ä–µ–∑ GPT-4
        analysis = await _analyze_conversation_deep(messages, existing_patterns, existing_insights)
        
        if not analysis:
            return
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–Ω—Å–∞–π—Ç—ã
        if analysis.get('insights'):
            await _add_insights(user_id, analysis['insights'], existing_patterns)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º related patterns
        if existing_patterns:
            await _update_related_patterns(user_id, existing_patterns)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º learning preferences
        if analysis.get('learning'):
            await _update_learning_preferences(user_id, analysis['learning'])
        
        logger.info(f"Deep analysis complete: {len(analysis.get('insights', []))} insights generated")
        
    except Exception as e:
        logger.error(f"Deep analysis failed: {e}")


async def _analyze_conversation_deep(
    messages: list[dict],
    existing_patterns: list[dict],
    existing_insights: list[dict]
) -> Optional[dict]:
    """
    GPT-4 –≥–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ (insights + recommendations)
    """
    conversation_text = "\n".join([
        f"{msg['role']}: {msg['content']}" 
        for msg in messages[-30:]
    ])
    
    patterns_summary = "\n".join([
        f"- [{p['type']}] {p['title']}: {p['description']} (occurs: {p.get('occurrences', 1)}x)"
        for p in existing_patterns[:15]
    ])
    
    prompt = f"""
Deep analysis of user's behavioral patterns and conversation history.

CONVERSATION (last 30 messages):
{conversation_text}

IDENTIFIED PATTERNS:
{patterns_summary if patterns_summary else 'No patterns yet'}

Tasks:
1. Generate 1-2 HIGH-LEVEL INSIGHTS from patterns
2. Provide actionable RECOMMENDATIONS
3. Identify what communication style WORKS WELL vs DOESN'T WORK

Return JSON:
{{
  "insights": [
    {{
      "category": "personality|behavior|emotional",
      "title": "Insight title",
      "description": "Detailed description connecting multiple patterns",
      "impact": "negative|neutral|positive",
      "recommendations": ["action1", "action2"],
      "derived_from_pattern_titles": ["pattern title 1", "pattern title 2"],
      "priority": "high|medium|low"
    }}
  ],
  "learning": {{
    "works_well": ["what works for this user"],
    "doesnt_work": ["what doesn't work"]
  }}
}}
"""
    
    try:
        response = await client.chat.completions.create(
            model="gpt-4o",  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–ª–Ω—É—é –≤–µ—Ä—Å–∏—é –¥–ª—è deep analysis
            messages=[
                {"role": "system", "content": "You are an expert psychologist providing deep insights."},
                {"role": "user", "content": prompt}
            ],
            response_format={"type": "json_object"},
            temperature=0.4
        )
        
        result = json.loads(response.choices[0].message.content)
        return result
        
    except Exception as e:
        logger.error(f"GPT-4 deep analysis failed: {e}")
        return None


# ==========================================
# üîÑ –î–ï–î–£–ü–õ–ò–ö–ê–¶–ò–Ø –ò –ú–ï–†–î–ñ –ü–ê–¢–¢–ï–†–ù–û–í
# ==========================================

async def _add_patterns_with_dedup(
    user_id: int,
    new_patterns: list[dict],
    existing_patterns: list[dict]
):
    """
    –î–æ–±–∞–≤–∏—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç—ã —á–µ—Ä–µ–∑ embeddings
    """
    for new_pattern in new_patterns:
        try:
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è embedding
            pattern_text = f"{new_pattern['title']} {new_pattern['description']}"
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç
            is_dup, duplicate, similarity = await embedding_service.is_duplicate(
                pattern_text,
                existing_patterns,
                text_key='description',
                threshold=0.85
            )
            
            if is_dup:
                # –ú–µ—Ä–¥–∂–∏–º —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º
                duplicate['occurrences'] = duplicate.get('occurrences', 1) + 1
                duplicate['evidence'].extend(new_pattern.get('evidence', []))
                duplicate['last_detected'] = datetime.now().isoformat()
                duplicate['confidence'] = max(duplicate['confidence'], new_pattern.get('confidence', 0.7))
                
                logger.info(f"Merged pattern: {new_pattern['title']} ‚Üí {duplicate['title']} (similarity: {similarity:.2f})")
            else:
                # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–π
                new_pattern['id'] = str(uuid.uuid4())
                new_pattern['first_detected'] = datetime.now().isoformat()
                new_pattern['last_detected'] = datetime.now().isoformat()
                new_pattern['occurrences'] = 1
                new_pattern['related_patterns'] = []
                
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º embedding
                new_pattern['embedding'] = await embedding_service.get_embedding(pattern_text)
                
                existing_patterns.append(new_pattern)
                
                logger.info(f"Added new pattern: {new_pattern['title']}")
        
        except Exception as e:
            logger.error(f"Failed to process pattern: {e}")
            continue
    
    # Limit: –º–∞–∫—Å–∏–º—É–º 20 –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ (—É–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ —Å –Ω–∏–∑–∫–∏–º confidence)
    if len(existing_patterns) > 20:
        existing_patterns.sort(
            key=lambda x: (x.get('confidence', 0.5), x.get('occurrences', 1)),
            reverse=True
        )
        existing_patterns = existing_patterns[:20]
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    await user_profile.update_patterns(user_id, existing_patterns)


async def _update_related_patterns(user_id: int, patterns: list[dict]):
    """
    –û–±–Ω–æ–≤–∏—Ç—å related_patterns —á–µ—Ä–µ–∑ semantic similarity
    """
    for i, pattern in enumerate(patterns):
        if 'embedding' not in pattern or not pattern['embedding']:
            continue
        
        # –ù–∞—Ö–æ–¥–∏–º 3 –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ—Ö–æ–∂–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–∞ (–∏—Å–∫–ª—é—á–∞—è —Å–µ–±—è)
        other_patterns = [p for j, p in enumerate(patterns) if j != i]
        
        related = await embedding_service.find_similar_items(
            pattern['embedding'],
            other_patterns,
            threshold=0.70,
            top_k=3
        )
        
        pattern['related_patterns'] = [p['id'] for p, _ in related]
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª—ë–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
    await user_profile.update_patterns(user_id, patterns)


# ==========================================
# üí° –ò–ù–°–ê–ô–¢–´
# ==========================================

async def _add_insights(user_id: int, new_insights: list[dict], existing_patterns: list[dict]):
    """
    –î–æ–±–∞–≤–∏—Ç—å –∏–Ω—Å–∞–π—Ç—ã (—Å —Å–≤—è–∑—å—é –∫ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º)
    """
    profile = await user_profile.get_or_create(user_id)
    existing_insights = profile.insights.get('insights', [])
    
    for insight in new_insights:
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º ID
        insight['id'] = str(uuid.uuid4())
        insight['created_at'] = datetime.now().isoformat()
        insight['last_updated'] = datetime.now().isoformat()
        
        # –°–≤—è–∑—ã–≤–∞–µ–º —Å –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º–∏ (–ø–æ title)
        derived_titles = insight.get('derived_from_pattern_titles', [])
        insight['derived_from'] = [
            p['id'] for p in existing_patterns
            if p['title'] in derived_titles
        ]
        
        existing_insights.append(insight)
    
    # Limit: –º–∞–∫—Å–∏–º—É–º 10 –∏–Ω—Å–∞–π—Ç–æ–≤
    if len(existing_insights) > 10:
        existing_insights = existing_insights[-10:]
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    await user_profile.update_insights(user_id, existing_insights)


# ==========================================
# üòä EMOTIONAL STATE
# ==========================================

async def _update_emotional_state(user_id: int, mood_data: dict):
    """
    –û–±–Ω–æ–≤–∏—Ç—å —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
    """
    profile = await user_profile.get_or_create(user_id)
    emotional_state = profile.emotional_state
    
    # –û–±–Ω–æ–≤–ª—è–µ–º —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
    emotional_state['current_mood'] = mood_data.get('current_mood', 'neutral')
    emotional_state['stress_level'] = mood_data.get('stress_level', 'medium')
    emotional_state['energy_level'] = mood_data.get('energy_level', 'medium')
    
    # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é (limit: –ø–æ—Å–ª–µ–¥–Ω–∏–µ 30 –¥–Ω–µ–π)
    mood_history = emotional_state.get('mood_history', [])
    today = datetime.now().date().isoformat()
    
    # –£–¥–∞–ª—è–µ–º —Å–µ–≥–æ–¥–Ω—è—à–Ω—é—é –∑–∞–ø–∏—Å—å –µ—Å–ª–∏ –µ—Å—Ç—å (–±—É–¥–µ–º –æ–±–Ω–æ–≤–ª—è—Ç—å)
    mood_history = [m for m in mood_history if m.get('date') != today]
    
    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—É—é
    mood_history.append({
        'date': today,
        'mood': mood_data.get('current_mood'),
        'triggers': mood_data.get('triggers', [])
    })
    
    # Limit: –ø–æ—Å–ª–µ–¥–Ω–∏–µ 30 –∑–∞–ø–∏—Å–µ–π
    emotional_state['mood_history'] = mood_history[-30:]
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    from database.database import db
    from sqlalchemy import update
    from database.models.user_profile import UserProfile
    
    async with db() as session:
        await session.execute(
            update(UserProfile)
            .where(UserProfile.user_id == user_id)
            .values(
                emotional_state=emotional_state,
                updated_at=datetime.now()
            )
        )
        await session.commit()


# ==========================================
# üéì LEARNING PREFERENCES
# ==========================================

async def _update_learning_preferences(user_id: int, learning_data: dict):
    """
    –û–±–Ω–æ–≤–∏—Ç—å learning preferences (—á—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç/–Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç)
    """
    profile = await user_profile.get_or_create(user_id)
    learning_prefs = profile.learning_preferences
    
    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ insights (–±–µ–∑ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤)
    works_well = set(learning_prefs.get('works_well', []))
    doesnt_work = set(learning_prefs.get('doesnt_work', []))
    
    works_well.update(learning_data.get('works_well', []))
    doesnt_work.update(learning_data.get('doesnt_work', []))
    
    # Limit: –ø–æ 10 –∫–∞–∂–¥–æ–≥–æ
    learning_prefs['works_well'] = list(works_well)[-10:]
    learning_prefs['doesnt_work'] = list(doesnt_work)[-10:]
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    from database.database import db
    from sqlalchemy import update
    from database.models.user_profile import UserProfile
    
    async with db() as session:
        await session.execute(
            update(UserProfile)
            .where(UserProfile.user_id == user_id)
            .values(
                learning_preferences=learning_prefs,
                updated_at=datetime.now()
            )
        )
        await session.commit()


# ==========================================
# üéØ PUBLIC API
# ==========================================

async def analyze_if_needed(user_id: int, assistant_type: str = 'helper'):
    """
    –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω—É–∂–µ–Ω –ª–∏ –∞–Ω–∞–ª–∏–∑ –∏ –∑–∞–ø—É—Å—Ç–∏—Ç—å –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    
    –¢—Ä–∏–≥–≥–µ—Ä—ã:
    - –ü–æ—Å–ª–µ 5 —Å–æ–æ–±—â–µ–Ω–∏–π ‚Üí quick analysis
    - –ü–æ—Å–ª–µ 20 —Å–æ–æ–±—â–µ–Ω–∏–π ‚Üí deep analysis
    
    Args:
        user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        assistant_type: –¢–∏–ø –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
    """
    if not is_feature_enabled('ENABLE_PATTERN_ANALYSIS'):
        return
    
    # –°—á–∏—Ç–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è
    message_count = await conversation_history.count_messages(user_id, assistant_type)
    
    # Quick analysis –∫–∞–∂–¥—ã–µ 5 —Å–æ–æ–±—â–µ–Ω–∏–π
    if message_count > 0 and message_count % 5 == 0:
        await quick_analysis(user_id, assistant_type)
    
    # Deep analysis –∫–∞–∂–¥—ã–µ 20 —Å–æ–æ–±—â–µ–Ω–∏–π
    if message_count > 0 and message_count % 20 == 0:
        await deep_analysis(user_id, assistant_type)

