"""
üìù Adaptive Formatting - –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–æ–≤ –±–æ—Ç–∞

–ó–∞—á–µ–º:
- –ö–æ—Ä–æ—Ç–∫–∏–µ –æ—Ç–≤–µ—Ç—ã (< 50 —Å–ª–æ–≤) –Ω–µ –Ω—É–∂–Ω–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å - plain text
- –°—Ä–µ–¥–Ω–∏–µ (50-100) - –º–∏–Ω–∏–º–∞–ª—å–Ω–æ (–≤—ã–¥–µ–ª—è–µ–º action verbs)
- –î–ª–∏–Ω–Ω—ã–µ (100-300) - —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ (–∑–∞–≥–æ–ª–æ–≤–∫–∏, —Å–ø–∏—Å–∫–∏)
- –û—á–µ–Ω—å –¥–ª–∏–Ω–Ω—ã–µ (300+) - –ø–æ–ª–Ω–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ (—Å–µ–∫—Ü–∏–∏, highlights)

–õ–æ–≥–∏–∫–∞:
- Ultra brief: NO formatting (plain text)
- Brief: minimal (bold action verbs)
- Medium: structured (headers, lists)
- Detailed: full formatting (sections, emojis, quotes)

–£—á–∏—Ç—ã–≤–∞–µ–º learning_preferences: –µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –ª—é–±–∏—Ç bold/—Å–ø–∏—Å–∫–∏ ‚Üí –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º

–ê–≤—Ç–æ—Ä: AI Agent Team
–°–æ–∑–¥–∞–Ω: 2025-10-31
"""

import logging
import re
from typing import Iterable, Optional

logger = logging.getLogger(__name__)

_SENTENCE_BOUNDARY_REGEX = re.compile(r'(?<=[.!?])\s+(?=[A-Z–ê-–Ø–Å])')
_MULTISPACE_REGEX = re.compile(r'[ \t]+')
_LABEL_PATTERN = re.compile(
    r'(?im)^(?P<prefix>[ \t‚Ä¢\-]*)\b(?P<label>'
    r'–í–∞–∂–Ω–æ|–ò—Ç–æ–≥–æ|–®–∞–≥|–í–æ–ø—Ä–æ—Å|–°—É—Ç—å|–†–µ—Å—É—Ä—Å|–ü—Ä–∞–∫—Ç–∏–∫–∞|–ù–∞–±–ª—é–¥–µ–Ω–∏–µ|–§–∏–Ω–∞–ª|–í—ã–≤–æ–¥'
    r')\b\s*:(?P<rest>[^\n]*)'
)
_KEYWORD_PHRASES_MEDIUM = [
    '—Ü–∏–∫–ª –∏–∑–±–µ–≥–∞–Ω–∏—è',
    '—Å–∫—Ä—ã—Ç—ã–π –º–æ—Ç–∏–≤',
    '—Ç–æ—á–∫–∞ —Ä–æ—Å—Ç–∞',
    '–±–ª–æ–∫–∏—Ä—É—é—â–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞',
    '–æ–ø–æ—Ä–Ω—ã–π —Ä–µ—Å—É—Ä—Å',
    '–≤–µ–∫—Ç–æ—Ä',
    '–ø–∞—Ç—Ç–µ—Ä–Ω',
    '—Ä–µ—Å—É—Ä—Å',
]
_KEYWORD_PHRASES_DETAILED = _KEYWORD_PHRASES_MEDIUM + ['–ø–æ–≤—Ç–æ—Ä—è—é—â–∞—è—Å—è –ø–µ—Ç–ª—è', '–¥–∏–Ω–∞–º–∏–∫–∞', '–∫–æ–Ω—Ç—Ä–∞—Å—Ç']
_LEVEL_SETTINGS = {
    'minimal': {'max_words': 45, 'max_sentences': 2},
    'medium': {'max_words': 60, 'max_sentences': 2},
    'detailed': {'max_words': 80, 'max_sentences': 3},
}
_QUESTION_FOCUS_REGEX = re.compile(
    r'\b(—á—Ç–æ –∏–º–µ–Ω–Ω–æ|—á—Ç–æ –∏–º–µ–Ω–Ω–æ —Ç—ã|—á—Ç–æ –∏–º–µ–Ω–Ω–æ –≤—ã|—á—Ç–æ –∏–º–µ–Ω–Ω–æ —Å–µ–π—á–∞—Å|—á—Ç–æ –∏–º–µ–Ω–Ω–æ|—á—Ç–æ|–∫–∞–∫|–∑–∞—á–µ–º|–ø–æ—á–µ–º—É|–∫–æ–≥–¥–∞|–∫—É–¥–∞|–≥–¥–µ|–∫—Ç–æ|–∫–∞–∫–æ–π|–∫–∞–∫–∞—è|–∫–∞–∫–æ–µ|–∫–æ—Ç–æ—Ä—ã–π)\b',
    flags=re.IGNORECASE
)


def format_bot_message(
    text: str,
    message_length_preference: str,
    learning_preferences: Optional[dict] = None,
    assistant_type: Optional[str] = None
) -> str:
    """
    –ê–¥–∞–ø—Ç–∏–≤–Ω–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –±–æ—Ç–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –¥–ª–∏–Ω—ã –∏ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π
    
    Args:
        text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç –æ—Ç GPT
        message_length_preference: ultra_brief|brief|medium|detailed
        learning_preferences: –ß—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç/–Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        
    Returns:
        –û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç (HTML –¥–ª—è Telegram)
        
    Examples:
        >>> format_bot_message("–ü–æ–ø—Ä–æ–±—É–π —Å–¥–µ–ª–∞—Ç—å —ç—Ç–æ.", "ultra_brief", None)
        "–ü–æ–ø—Ä–æ–±—É–π —Å–¥–µ–ª–∞—Ç—å —ç—Ç–æ."  # No formatting
        
        >>> format_bot_message("–ù–∞—á–Ω–∏ —Å –º–∞–ª–æ–≥–æ. –ü–æ–ø—Ä–æ–±—É–π –≤—ã–¥–µ–ª–∏—Ç—å 5 –º–∏–Ω—É—Ç.", "brief", None)
        "<b>–ù–∞—á–Ω–∏</b> —Å –º–∞–ª–æ–≥–æ. <b>–ü–æ–ø—Ä–æ–±—É–π</b> –≤—ã–¥–µ–ª–∏—Ç—å 5 –º–∏–Ω—É—Ç."  # Bold verbs
    """
    if not text or not text.strip():
        return text
    
    word_count = len(text.split())
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º learning preferences
    if learning_preferences:
        doesnt_work = learning_preferences.get('doesnt_work', [])
        
        # –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –ª—é–±–∏—Ç —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ ‚Üí –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
        formatting_dislikes = ['—Å–ø–∏—Å–∫–∏', 'bold', '–∂–∏—Ä–Ω—ã–π —Ç–µ–∫—Å—Ç', 'formatting', 'emojis']
        if any(dislike.lower() in ' '.join(doesnt_work).lower() for dislike in formatting_dislikes):
            logger.debug("Formatting skipped: user doesn't like formatting")
            return text
    
    # ==========================================
    # ULTRA BRIEF (< 50 words): NO FORMATTING
    # ==========================================
    if word_count < 50:
        logger.debug(f"Formatting: ultra brief ({word_count} words), light formatting")
        return _structure_text(text, level='minimal', word_count=word_count)
    
    # ==========================================
    # BRIEF (50-100 words): MINIMAL FORMATTING
    # ==========================================
    elif word_count < 100:
        logger.debug(f"Formatting: brief ({word_count} words), minimal formatting")
        return _apply_minimal_formatting(text)
    
    # ==========================================
    # MEDIUM (100-300 words): STRUCTURED
    # ==========================================
    elif word_count < 300:
        logger.debug(f"Formatting: medium ({word_count} words), structured formatting")
        return _apply_medium_formatting(text)
    
    # ==========================================
    # DETAILED (300+ words): FULL FORMATTING
    # ==========================================
    else:
        logger.debug(f"Formatting: detailed ({word_count} words), full formatting")
        return _apply_detailed_formatting(text)


def _apply_minimal_formatting(text: str) -> str:
    """
    Brief: –≤—ã–¥–µ–ª—è–µ–º —Ç–æ–ª—å–∫–æ action verbs (–ø—Ä–∏–∑—ã–≤—ã –∫ –¥–µ–π—Å—Ç–≤–∏—é)
    
    Examples:
        "–ù–∞—á–Ω–∏ —Å –º–∞–ª–æ–≥–æ" ‚Üí "<b>–ù–∞—á–Ω–∏</b> —Å –º–∞–ª–æ–≥–æ"
        "–ü–æ–ø—Ä–æ–±—É–π –≤—ã–¥–µ–ª–∏—Ç—å 5 –º–∏–Ω—É—Ç" ‚Üí "<b>–ü–æ–ø—Ä–æ–±—É–π</b> –≤—ã–¥–µ–ª–∏—Ç—å 5 –º–∏–Ω—É—Ç"
    """
    # –°–ø–∏—Å–æ–∫ action verbs (–ø—Ä–∏–∑—ã–≤—ã –∫ –¥–µ–π—Å—Ç–≤–∏—é)
    action_verbs = [
        '–Ω–∞—á–Ω–∏', '—Å–¥–µ–ª–∞–π', '–ø–æ–ø—Ä–æ–±—É–π', '–≤—ã–¥–µ–ª–∏', '–∑–∞–ø–∏—à–∏',
        '–ø–æ–¥—É–º–∞–π', '–ø—Ä–æ—á–∏—Ç–∞–π', '–Ω–∞–ø–∏—à–∏', '—Å–ø—Ä–æ—Å–∏', '–æ–±—Ä–∞—Ç–∏',
        '–ø–æ–∑–≤–æ–Ω–∏', '—Å—Ö–æ–¥–∏', '–ø–æ–≥–æ–≤–æ—Ä–∏', '—Ä–µ—à–∏', '–≤—ã–±–µ—Ä–∏',
        '–æ—Ç–¥–æ—Ö–Ω–∏', '–æ—Å—Ç–∞–Ω–æ–≤–∏—Å—å', '–ø–æ–¥–æ–∂–¥–∏', '–ø–æ—Å–ª—É—à–∞–π', '–ø–æ—Å–º–æ—Ç—Ä–∏'
    ]
    
    # –í—ã–¥–µ–ª—è–µ–º —Ç–æ–ª—å–∫–æ –≤ –Ω–∞—á–∞–ª–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏–ª–∏ –ø–æ—Å–ª–µ –ø–µ—Ä–µ–Ω–æ—Å–∞
    for verb in action_verbs:
        # Case-insensitive –∑–∞–º–µ–Ω–∞
        text = re.sub(
            rf'(^|\n)({verb})\b',
            r'\1<b>\2</b>',
            text,
            flags=re.IGNORECASE | re.MULTILINE
        )
    
    return _structure_text(text, level='minimal', word_count=len(text.split()))


def _apply_medium_formatting(text: str) -> str:
    """
    Medium: —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ + —Å–ø–∏—Å–∫–∏ + –≤—ã–¥–µ–ª–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Ñ—Ä–∞–∑
    """
    lines = text.split('\n')
    result = []
    
    # 1. –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º numbered lists –≤ bullet points
    for line in lines:
        stripped = line.strip()
        
        # Numbered list (1. 2. 3.)
        if re.match(r'^\d+\.\s', stripped):
            line = '  ‚Ä¢ ' + re.sub(r'^\d+\.\s', '', stripped)
        
        # Dash list (-)
        elif stripped.startswith('- '):
            line = '  ‚Ä¢ ' + stripped[2:]
        
        result.append(line)
    
    # 2. –í—ã–¥–µ–ª—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —Ñ—Ä–∞–∑—ã
    formatted = '\n'.join(result)
    
    # "–í–∞–∂–Ω–æ:", "–°–æ–≤–µ—Ç:", "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:" –∏ —Ç.–¥.
    key_phrases = ['–≤–∞–∂–Ω–æ', '—Å–æ–≤–µ—Ç', '—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è', '–ø–æ–º–Ω–∏', '–æ–±—Ä–∞—Ç–∏ –≤–Ω–∏–º–∞–Ω–∏–µ', '–∑–∞–º–µ—Ç—å']
    for phrase in key_phrases:
        formatted = re.sub(
            rf'\b({phrase})\b:',
            r'<b>\1</b>:',
            formatted,
            flags=re.IGNORECASE
        )
    
    # 3. –í—ã–¥–µ–ª—è–µ–º –∏–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –Ω–∞—á–∞–ª–µ (–µ—Å–ª–∏ –µ—Å—Ç—å)
    lines = formatted.split('\n')
    if lines and ',' in lines[0]:
        parts = lines[0].split(',', 1)
        # –ï—Å–ª–∏ –ø–µ—Ä–≤–æ–µ —Å–ª–æ–≤–æ –∫–æ—Ä–æ—Ç–∫–æ–µ (–∏–º—è) ‚Üí –≤—ã–¥–µ–ª—è–µ–º
        if len(parts[0].split()) == 1 and len(parts[0]) < 15:
            lines[0] = f"<b>{parts[0]}</b>,{parts[1]}"
    
    formatted = '\n'.join(lines)
    return _structure_text(formatted, level='medium', word_count=len(formatted.split()))


def _apply_detailed_formatting(text: str) -> str:
    """
    Detailed: —Å–µ–∫—Ü–∏–∏ + –ø–æ–ª–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ + emojis + —Ü–∏—Ç–∞—Ç—ã
    """
    # 1. Detect sections by keywords
    sections = {
        '–ø–∞—Ç—Ç–µ—Ä–Ω': 'üß†',
        '–∏–Ω—Å–∞–π—Ç': 'üí°',
        '—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü': 'üìå',
        '–ø—Ä–∏–º–µ—Ä—ã': 'üìù',
        '—à–∞–≥–∏': 'üî¢',
        '–∏—Ç–æ–≥–æ': '‚úÖ',
        '–≤–∞–∂–Ω–æ': '‚ö†Ô∏è',
        '–ø–æ–º–Ω–∏': 'üéØ',
        '—Ç–≤–æ–π': 'üí¨',
        '–∞–Ω–∞–ª–∏–∑': 'üîç'
    }
    
    formatted = text
    
    # –î–æ–±–∞–≤–ª—è–µ–º emojis –∫ —Å–µ–∫—Ü–∏—è–º
    for keyword, emoji in sections.items():
        # –ù–∞—Ö–æ–¥–∏–º —Å—Ç—Ä–æ–∫–∏ –Ω–∞—á–∏–Ω–∞—é—â–∏–µ—Å—è —Å keyword (case-insensitive)
        formatted = re.sub(
            rf'^({keyword}.*?):\s*',
            rf'<b>{emoji} \1:</b>\n',
            formatted,
            flags=re.IGNORECASE | re.MULTILINE
        )
    
    # 2. –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Å–ø–∏—Å–∫–∏
    lines = formatted.split('\n')
    result = []
    
    for line in lines:
        stripped = line.strip()
        
        # Numbered list ‚Üí bullet
        if re.match(r'^\d+\.\s', stripped):
            line = '  ‚Ä¢ ' + re.sub(r'^\d+\.\s', '', stripped)
        
        # Dash list ‚Üí bullet
        elif stripped.startswith('- '):
            line = '  ‚Ä¢ ' + stripped[2:]
        
        result.append(line)
    
    # 3. –í—ã–¥–µ–ª—è–µ–º —Ü–∏—Ç–∞—Ç—ã (italic)
    formatted = '\n'.join(result)
    
    # "–¢—ã –≥–æ–≤–æ—Ä–∏–ª: '—Ü–∏—Ç–∞—Ç–∞'" ‚Üí italic –¥–ª—è —Ü–∏—Ç–∞—Ç—ã
    formatted = re.sub(
        r"'([^']+)'",
        r"<i>'\1'</i>",
        formatted
    )
    formatted = re.sub(
        r'"([^"]+)"',
        r'<i>"\1"</i>',
        formatted
    )
    
    # 4. –í—ã–¥–µ–ª—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
    key_words = ['–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û', '–í–ê–ñ–ù–û', '–ö–†–ò–¢–ò–ß–ù–û', '–°–†–û–ß–ù–û']
    for word in key_words:
        formatted = re.sub(
            rf'\b({word})\b',
            r'<b>\1</b>',
            formatted,
            flags=re.IGNORECASE
        )
    return _structure_text(formatted, level='detailed', word_count=len(formatted.split()))


__all__ = ['format_bot_message']


def _structure_text(text: str, *, level: str, word_count: int | None = None) -> str:
    normalized = _normalize_text(text)
    total_words = word_count if word_count is not None else len(normalized.split())
    
    paragraphs = _split_paragraphs(normalized)
    settings = _LEVEL_SETTINGS.get(level, _LEVEL_SETTINGS['medium'])
    expanded: list[str] = []
    for block in paragraphs:
        expanded.extend(
            _split_long_paragraph(
                block,
                max_words=settings['max_words'],
                max_sentences=settings['max_sentences']
            )
        )
    
    highlighted = [_apply_paragraph_highlights(block, level=level) for block in expanded]
    
    allow_question_focus = level in ('medium', 'detailed') and total_words >= 120
    highlighted = _highlight_final_question(
        highlighted,
        enable_focus=allow_question_focus
    )
    
    return "\n\n".join(part for part in highlighted if part).strip()


def _normalize_text(text: str) -> str:
    cleaned = text.replace('\r\n', '\n').strip()
    cleaned = _MULTISPACE_REGEX.sub(' ', cleaned)
    cleaned = re.sub(r'\n[ \t]+', '\n', cleaned)
    return cleaned


def _split_paragraphs(text: str) -> list[str]:
    raw_blocks = [block.strip() for block in text.split('\n\n') if block.strip()]
    if raw_blocks:
        return raw_blocks
    return [text.strip()] if text.strip() else []


def _split_long_paragraph(
    paragraph: str,
    *,
    max_words: int,
    max_sentences: int
) -> list[str]:
    if not paragraph:
        return []
    
    if _looks_like_list(paragraph):
        return [paragraph.strip()]
    
    sentences = _split_sentences(paragraph)
    if not sentences:
        return [paragraph.strip()]
    
    buckets: list[str] = []
    buffer: list[str] = []
    word_counter = 0
    sentence_counter = 0
    
    for sentence in sentences:
        sentence_words = len(sentence.split())
        buffer.append(sentence)
        word_counter += sentence_words
        sentence_counter += 1
        
        if word_counter >= max_words or sentence_counter >= max_sentences:
            buckets.append(' '.join(buffer).strip())
            buffer = []
            word_counter = 0
            sentence_counter = 0
    
    if buffer:
        buckets.append(' '.join(buffer).strip())
    
    return buckets or [paragraph.strip()]


def _split_sentences(paragraph: str) -> list[str]:
    if not paragraph:
        return []
    sentences = _SENTENCE_BOUNDARY_REGEX.split(paragraph)
    return [sentence.strip() for sentence in sentences if sentence.strip()]


def _looks_like_list(paragraph: str) -> bool:
    lines = [line.strip() for line in paragraph.split('\n') if line.strip()]
    if not lines:
        return False
    
    bullet_lines = sum(
        1
        for line in lines
        if re.match(r'^([‚Ä¢\-‚Äì‚Äî]|(\d+\.))\s', line)
    )
    return bullet_lines >= max(1, len(lines) // 2)


def _apply_paragraph_highlights(paragraph: str, *, level: str) -> str:
    if not paragraph:
        return paragraph
    
    updated = _italicize_quotes(paragraph)
    
    if level in ('medium', 'detailed'):
        updated = _highlight_labels(updated)
        updated = _highlight_keywords(updated, phrases=_KEYWORD_PHRASES_MEDIUM)
    
    if level == 'detailed':
        updated = _highlight_keywords(updated, phrases=_KEYWORD_PHRASES_DETAILED)
    
    return updated


def _italicize_quotes(text: str) -> str:
    text = re.sub(
        r'(?<!<i>)¬´([^¬ª]+)¬ª(?!</i>)',
        r'<i>¬´\1¬ª</i>',
        text
    )
    text = re.sub(
        r'(?<!<i>)"([^"]+)"(?!</i>)',
        r'<i>"\1"</i>',
        text
    )
    text = re.sub(
        r"(?<!<i>)'([^']+)'(?!</i>)",
        r"<i>'\1'</i>",
        text
    )
    return text


def _highlight_labels(text: str) -> str:
    def _replace(match: re.Match) -> str:
        prefix = match.group('prefix')
        label = match.group('label')
        rest = match.group('rest')
        if '<b>' in match.group(0):
            return match.group(0)
        return f"{prefix}<b>{label}:</b>{rest}"
    
    return _LABEL_PATTERN.sub(_replace, text)


def _highlight_keywords(text: str, *, phrases: Iterable[str]) -> str:
    updated = text
    for phrase in phrases:
        updated = _bold_phrase(updated, phrase)
    return updated


def _bold_phrase(text: str, phrase: str) -> str:
    if not phrase or not text:
        return text
    
    if re.search(rf'<b>[^<]*{re.escape(phrase)}[^<]*</b>', text, flags=re.IGNORECASE):
        return text
    
    return re.sub(
        rf'(?i)\b({re.escape(phrase)})\b',
        lambda match: f"<b>{match.group(1)}</b>",
        text,
        count=1
    )


def _highlight_final_question(
    paragraphs: list[str],
    *,
    enable_focus: bool
) -> list[str]:
    if not paragraphs:
        return paragraphs
    
    last = paragraphs[-1]
    sentences = _split_sentences(last)
    if not sentences:
        return paragraphs
    
    final_sentence = sentences[-1]
    if not final_sentence.endswith('?'):
        return paragraphs
    
    if not enable_focus:
        return paragraphs
    
    if '<b>' in final_sentence:
        paragraphs[-1] = ' '.join(sentences).strip()
        return paragraphs
    
    focus = _QUESTION_FOCUS_REGEX.search(final_sentence)
    if focus:
        word = focus.group(0)
        sentences[-1] = (
            final_sentence[:focus.start()]
            + f"<b>{word}</b>"
            + final_sentence[focus.end():]
        )
        paragraphs[-1] = ' '.join(sentences).strip()
        return paragraphs
    
    # Fallback: highlight last meaningful word (but not whole sentence)
    tokens = final_sentence.rstrip(' ?').split()
    if len(tokens) >= 2:
        target = tokens[-1]
        if target and '<b>' not in target:
            sentences[-1] = final_sentence.rsplit(target, 1)[0] + f"<b>{target}</b>?"
            paragraphs[-1] = ' '.join(sentences).strip()
    
    return paragraphs

